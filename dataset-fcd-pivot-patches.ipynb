{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f4907d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nibabel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.core.debugger import set_trace\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from models.v2v import V2VModel\n",
    "\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from utils import show_slices, check_patch, pad_arrays, normalized, load, create_dicts\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "N_CPU = cpu_count()\n",
    "\n",
    "SEED = 42\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0336b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBrainMaskPatchLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, config, train=True):\n",
    "        \n",
    "        self.root = config.root\n",
    "        self.metadata_path = config.metadata_path\n",
    "        self.train = train\n",
    "        self.patch_size = config.patch_size\n",
    "        self.use_features = config.use_features\n",
    "        \n",
    "        self.concatenate_adjacent_patch = config.concatenate_adjacent_patch\n",
    "        self.difference_with_adjacent_patch = config.concatenate_adjacent_patch\n",
    "        \n",
    "        metadata_key = 'train' if train else 'test' \n",
    "        self.metadata = pd.read_csv(self.metadata_path).query(f\"is_train == {metadata_key}\")\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        metaindex = self.metadata.iloc[idx]\n",
    "        \n",
    "        label = 'tensor_' + metaindex.label\n",
    "        \n",
    "        tensor_dict = torch.load(os.path.join(self.root, label))\n",
    "        brain_tensor_torch = tensor_dict['brain']\n",
    "        mask_tensor_torch = tensor_dict['mask']\n",
    "        label_tensor_torch = tensor_dict['label']\n",
    "        \n",
    "        x,y,z = metaindex[['x','y','z']].astype(int)\n",
    "\n",
    "        x1,x2 = x-self.patch_size//2, x+self.patch_size//2\n",
    "        y1,y2 = y-self.patch_size//2, y+self.patch_size//2\n",
    "        z1,z2 = z-self.patch_size//2, z+self.patch_size//2\n",
    "\n",
    "        if self.use_features:\n",
    "            brain_patch = brain_tensor_torch[:,x1:x2,y1:y2,z1:z2] # [N_features,H,W,D] \n",
    "        else:\n",
    "            brain_patch = brain_tensor_torch[x1:x2,y1:y2,z1:z2].unsqueeze(0) # [1,H,W,D] \n",
    "            \n",
    "        label_patch = torch.tensor(metaindex.is_fcd, dtype=torch.long) # label\n",
    "    \n",
    "        return brain_patch, label_patch.unsqueeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddaaf38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load('../fcd_data/normalized_tensors/tensor_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106f640",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "916c0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_components = np.load('labels_info.npy', allow_pickle=True).item()\n",
    "single_component_keys = {k for k,v in labels_components.items() if len(v['cc3d'][0]) == 2}\n",
    "\n",
    "USE_GEOM_FEATURES = True\n",
    "GEOM_FEATURES = ['thickness', 'sulc', 'curv']\n",
    "\n",
    "root_label = '../fcd_data/normalized_label'\n",
    "root_data = '../fcd_data/normalized_data/'\n",
    "root_geom_features = '../fcd_data/preprocessed_data_anadezhda/'\n",
    "\n",
    "paths_dict = create_dicts(root_label,\n",
    "                         root_data,\n",
    "                         root_geom_features, \n",
    "                         single_component_keys,\n",
    "                         USE_GEOM_FEATURES, \n",
    "                         GEOM_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6257683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b5342d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = np.load('metadata.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c82ed",
   "metadata": {},
   "source": [
    "# Make metadata - smooth classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e44ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.device('cuda:2') == torch.device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cee16262",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE=50\n",
    "pad=PATCH_SIZE//2\n",
    "\n",
    "DEVICE = torch.device('cuda:3') #torch.device(2)\n",
    "W = torch.ones(1, 1, PATCH_SIZE+1, PATCH_SIZE+1, PATCH_SIZE+1, dtype=torch.float)#.to(DEVICE) \n",
    "W_sum = (PATCH_SIZE+1)**3\n",
    "\n",
    "PERC_THRESHOLD = 0.5 # how m uch tissue\n",
    "LABEL_THRESHOLD = 1000 # how much FCD pixels to be considered as FCD patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "628cffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv3d(1, 1, PATCH_SIZE+1, bias=False)\n",
    "conv.weight.data = W\n",
    "conv = conv.to(DEVICE)\n",
    "# torch.conv3d(input=mask_tensor_torch, weight=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84df23ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 28.6 s, total: 2min 13s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k='30'\n",
    "path_dict = paths_dict[k]\n",
    "brain_tensor, mask_tensor, label_tensor = load(path_dict) # float, bool, int\n",
    "\n",
    "X,Y,Z = mask_tensor.shape\n",
    "X_mean = X//2\n",
    "\n",
    "# get rid of a mid-brain\n",
    "thresh_mask = (np.arange(X) < (X_mean - pad)) | (np.arange(X) > (X_mean + pad))\n",
    "thresh_mask = np.tile(thresh_mask, (Y,Z,1)).transpose(2,0,1)\n",
    "mask_tensor = mask_tensor*(thresh_mask > 0)\n",
    "\n",
    "###########################\n",
    "# CREATE RELEVANT INDEXES #\n",
    "###########################\n",
    "xyz_grid = np.stack(np.meshgrid(np.arange(pad, X-pad), \n",
    "                                np.arange(pad, Y-pad), \n",
    "                                np.arange(pad, Z-pad), \n",
    "                                indexing='ij'), -1)\n",
    "\n",
    "mask_tensor_torch = torch.tensor(mask_tensor, \n",
    "                                 dtype=torch.float).to(DEVICE).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "#         p_perc = torch.conv3d(input=mask_tensor_torch, weight=W) / W_sum\n",
    "#         p_perc = p_perc.detach().cpu().numpy()\n",
    "#         l_sum = torch.conv3d(input=label_tensor_torch, weight=W)\n",
    "#         l_sum = l_sum.detach().cpu().numpy()\n",
    "\n",
    "label_tensor_torch = torch.tensor(label_tensor, \n",
    "                                  dtype=torch.float).to(DEVICE).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "p_perc = conv(mask_tensor_torch).detach().cpu().numpy()[0,0] \n",
    "l_sum = conv(label_tensor_torch).detach().cpu().numpy()[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6514b7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 286, 233, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b22a5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((241, 336, 283), torch.Size([1, 1, 241, 336, 283]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tensor.shape, mask_tensor_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6741b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 11s, sys: 8.75 s, total: 2min 20s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k='30'\n",
    "path_dict = paths_dict[k]\n",
    "brain_tensor, mask_tensor, label_tensor = load(path_dict) # float, bool, int\n",
    "\n",
    "X,Y,Z = mask_tensor.shape\n",
    "X_mean = X//2\n",
    "\n",
    "# get rid of a mid-brain\n",
    "thresh_mask = (np.arange(X) < (X_mean - pad)) | (np.arange(X) > (X_mean + pad))\n",
    "thresh_mask = np.tile(thresh_mask, (Y,Z,1)).transpose(2,0,1)\n",
    "mask_tensor = mask_tensor*(thresh_mask > 0)\n",
    "\n",
    "\n",
    "###########################\n",
    "# CREATE RELEVANT INDEXES #\n",
    "###########################\n",
    "xyz_grid = np.stack(np.meshgrid(np.arange(pad, X-pad), \n",
    "                                np.arange(pad, Y-pad), \n",
    "                                np.arange(pad, Z-pad), \n",
    "                                indexing='ij'), -1)\n",
    "\n",
    "xyz_grid = xyz_grid[mask_tensor[pad:-pad,pad:-pad,pad:-pad]]\n",
    "\n",
    "indexes_selected = Parallel(n_jobs=-1)(delayed(check_patch)(x,y,z,\\\n",
    "                                                            mask_tensor,\\\n",
    "                                                            label_tensor,\\\n",
    "                                                            pad) \\\n",
    "                                                       for x,y,z in xyz_grid)\n",
    "\n",
    "indexes_selected = list(filter(lambda x: x is not None, indexes_selected))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea55015",
   "metadata": {},
   "source": [
    "CUDA 2:\n",
    "\n",
    "CPU times: user 6min 14s, sys: 1min 53s, total: 8min 7s\n",
    "Wall time: 8min 3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd6849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                         | 0/69 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "torch.cuda.synchronize()\n",
    "for split_type, split_keys in metadata.items():\n",
    "    for k in tqdm(split_keys):\n",
    "        \n",
    "        path_dict = paths_dict[k]\n",
    "        brain_tensor, mask_tensor, label_tensor = load(path_dict) # float, bool, int\n",
    "     \n",
    "        X,Y,Z = mask_tensor.shape\n",
    "        X_mean = X//2\n",
    "        \n",
    "        # get rid of a mid-brain\n",
    "        thresh_mask = (np.arange(X) < (X_mean - pad)) | (np.arange(X) > (X_mean + pad))\n",
    "        thresh_mask = np.tile(thresh_mask, (Y,Z,1)).transpose(2,0,1)\n",
    "        mask_tensor = mask_tensor*(thresh_mask > 0)\n",
    "        \n",
    "        ###########################\n",
    "        # CREATE RELEVANT INDEXES #\n",
    "        ###########################\n",
    "        xyz_grid = np.stack(np.meshgrid(np.arange(pad, X-pad), \n",
    "                                        np.arange(pad, Y-pad), \n",
    "                                        np.arange(pad, Z-pad), \n",
    "                                        indexing='ij'), -1)\n",
    "        \n",
    "        mask_tensor_torch = torch.tensor(mask_tensor, \n",
    "                                         dtype=torch.float).to(DEVICE).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "#         p_perc = torch.conv3d(input=mask_tensor_torch, weight=W) / W_sum\n",
    "#         p_perc = p_perc.detach().cpu().numpy()\n",
    "#         l_sum = torch.conv3d(input=label_tensor_torch, weight=W)\n",
    "#         l_sum = l_sum.detach().cpu().numpy()\n",
    "        \n",
    "        label_tensor_torch = torch.tensor(label_tensor, \n",
    "                                          dtype=torch.float).to(DEVICE).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        p_perc = conv(mask_tensor_torch).cpu().numpy()[0,0] \n",
    "        l_sum = conv(label_tensor_torch).cpu().numpy()[0,0]\n",
    "\n",
    "#         torch.cuda.synchronize()\n",
    "        \n",
    "#         p_perc_mask = p_perc >= PERC_THRESHOLD\n",
    "#         mask_tensor = mask_tensor[pad:-pad, pad:-pad, pad:-pad]\n",
    "        \n",
    "#         # appropriate patches\n",
    "#         mask_tensor = (mask_tensor*p_perc_mask) # bool\n",
    "#         xyz_grid = xyz_grid[mask_tensor]\n",
    "        \n",
    "#         # corresponding values\n",
    "#         perc = p_perc[mask_tensor]\n",
    "#         lsum = l_sum[mask_tensor]\n",
    "#         fcd_bin = (lsum >= LABEL_THRESHOLD).astype(int)\n",
    "        \n",
    "#         df = pd.DataFrame(xyz_grid, columns=['x','y','z'])\n",
    "#         df['p_perc'] = perc\n",
    "#         df['l_sum'] = lsum\n",
    "#         df['is_train'] = split_type == 'train'\n",
    "#         df['label'] = k\n",
    "#         df['fcd'] = fcd_bin\n",
    "        \n",
    "        break\n",
    "    break\n",
    "#         df.to_csv(f'../fcd_data/indexes_selected/{split_type}_{k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42fa97ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 141, 236, 183)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_perc_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "284513c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 236, 183, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0236cccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 141, 236, 183)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac34652",
   "metadata": {},
   "source": [
    "# Make metadata - strict classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a18b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION_STEPS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_pivot_patches = defaultdict(dict)\n",
    "\n",
    "# for split_type, split_keys in metadata.items():\n",
    "    \n",
    "#     for k in split_keys:\n",
    "        \n",
    "#         path_dict = paths_dict[k]\n",
    "        \n",
    "        \n",
    "#         brain_tensor, mask_tensor, label_tensor = load(path_dict) # float, bool, int\n",
    "#         label_info = labels_components[k]\n",
    "#         center = label_info['center']\n",
    "        \n",
    "#         ###########\n",
    "#         # AUGMENT #\n",
    "#         ###########\n",
    "#         aug_iter = np.arange(-AUGMENTATION_STEPS, AUGMENTATION_STEPS+1)\n",
    "#         for shift in len(list(product(aug_iter, aug_iter, aug_iter))):\n",
    "#             info_patch = {}\n",
    "#             center_i = center + np.array(shift)\n",
    "#             info_patch['patch_center'] = center_i\n",
    "#             info_patch['subject'] = k\n",
    "#             info_patch['label'] = 1\n",
    "        \n",
    "#         X,Y,Z = mask_tensor.shape\n",
    "#         X_mean = X//2\n",
    "        \n",
    "#         # get rid of a mid-brain\n",
    "#         thresh_mask = (np.arange(X) < (X_mean - pad)) | (np.arange(X) > (X_mean + pad))\n",
    "#         thresh_mask = np.tile(thresh_mask, (Y,Z,1)).transpose(2,0,1)\n",
    "#         mask_tensor = mask_tensor*(thresh_mask > 0)\n",
    "        \n",
    "#         ###########################\n",
    "#         # CREATE RELEVANT INDEXES #\n",
    "#         ###########################\n",
    "#         xyz_grid = np.stack(np.meshgrid(np.arange(X), np.arange(Y), np.arange(Z), indexing='ij'), -1)\n",
    "#         xyz_grid = xyz_grid[mask_tensor]\n",
    "\n",
    "#         indexes_selected = Parallel(n_jobs=-1)(delayed(check_patch)(x,y,z,\\\n",
    "#                                                                     mask_tensor,\\\n",
    "#                                                                     label_tensor,\\\n",
    "#                                                                     pad) \\\n",
    "#                                                                for x,y,z in xyz_grid)\n",
    "\n",
    "#         indexes_selected = list(filter(lambda x: x is not None, indexes_selected))\n",
    "#         np.save('../fcd_data/indexes_selected/')\n",
    "#         break\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
