{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f4907d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nibabel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.core.debugger import set_trace\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from models.v2v import V2VModel\n",
    "\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from utils import show_slices, check_patch, get_symmetric_value, pad_arrays, normalized, load\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "N_CPU = cpu_count()\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9fee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBrainMaskPatchLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, config, train=True):\n",
    "        self.root = config.root\n",
    "        self.train = train\n",
    "        self.patch_size = config.patch_size\n",
    "        self.use_features = config.use_features\n",
    "\n",
    "        metadata_name = 'metadata_' + ('train' if train else 'test') \n",
    "        self.metadata = pd.read_csv(os.path.join(self.root, metadata_name))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        metaindex = self.metadata.iloc[idx]\n",
    "        \n",
    "        label = 'tensor_' + metaindex.label\n",
    "        tensor = torch.load(os.path.join(self.root, label))\n",
    "        x,y,z = metaindex[['x','y','z']].astype(int)\n",
    "\n",
    "        x1,x2 = x-self.patch_size//2, x+self.patch_size//2\n",
    "        y1,y2 = y-self.patch_size//2, y+self.patch_size//2\n",
    "        z1,z2 = z-self.patch_size//2, z+self.patch_size//2\n",
    "\n",
    "        if self.use_features:\n",
    "            brain_patch = tensor[0:-1,x1:x2,y1:y2,z1:z2] # brain \n",
    "        else:\n",
    "            brain_patch = tensor[0:1,x1:x2,y1:y2,z1:z2] # brain \n",
    "        label_patch = tensor[-1,x1:x2,y1:y2,z1:z2] # label\n",
    "    \n",
    "        return brain_patch, label_patch.unsqueeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106f640",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "916c0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GEOM_FEATURES = False\n",
    "GEOM_FEATURES = ['thickness', 'sulc', 'curv']\n",
    "patch_size=100\n",
    "pad=patch_size//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3406c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches_data_root = f'../fcd_data/patches_dataset_{patch_size}' + ('_features' if USE_GEOM_FEATURES else '')\n",
    "\n",
    "# if not os.path.isdir(patches_data_root):\n",
    "#     os.makedirs(patches_data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e6bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_dict = defaultdict(dict)\n",
    "for p in os.listdir('../fcd_data/normalized_label'):\n",
    "    \n",
    "    label = p.split('.')[0]\n",
    "    \n",
    "    sub_root = f'../fcd_data/normalized_data/sub-{label}/anat/'\n",
    "    brain_path = glob.glob(os.path.join(sub_root, '*Asym_desc-preproc_T1w.nii.gz'))[0]\n",
    "    mask_path = glob.glob(os.path.join(sub_root, '*Asym_desc-brain_mask.nii.gz'))[0]\n",
    "    label_path = f'../fcd_data/normalized_label/{p}' \n",
    "    \n",
    "    # features\n",
    "    if USE_GEOM_FEATURES:\n",
    "        absent_feature = False\n",
    "        for feature_name in GEOM_FEATURES:\n",
    "            feature_path = f'../fcd_data/preprocessed_data_anadezhda/{feature_name}/norm-{label}.nii'\n",
    "            if not os.path.isfile(feature_path):\n",
    "                absent_feature=True\n",
    "                continue\n",
    "            paths_dict[label][f'{feature_name}'] = feature_path\n",
    "        if absent_feature:\n",
    "            continue\n",
    "        \n",
    "    paths_dict[label]['label'] = label_path\n",
    "    paths_dict[label]['brain'] = brain_path    \n",
    "    paths_dict[label]['mask'] = mask_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdb52242",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_info = np.load('labels_info.npy', allow_pickle=True).item()\n",
    "labels_info = {k:v for k,v in labels_info.items() if len(v['cc3d'][0]) == 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35929ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys, test_keys = train_test_split(list(labels_info.keys()), test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a97ae77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = {'train':train_keys,\n",
    "              'test':test_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2e43dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cc3d': [array([0, 1], dtype=uint16), array([22911852,     4356])],\n",
       " 'd_s': [19, 26, 28],\n",
       " 'center': array([152, 212,  60])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_info['30']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c82ed",
   "metadata": {},
   "source": [
    "# Make metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION_STEPS = 2\n",
    "\n",
    "metadata_fcd_pivot_patches = defaultdict(dict)\n",
    "\n",
    "for split_type, split_keys in labels_all.items():\n",
    "    for k in split_keys:\n",
    "        path_dict = paths_dict[k]\n",
    "        info_patch = {}\n",
    "        \n",
    "        brain_tensor, mask_tensor, label_tensor = load(path_dict)\n",
    "        label_info = labels_info[k]\n",
    "        center = label_info['center']\n",
    "        \n",
    "        aug_iter = np.arange(-AUGMENTATION_STEPS, AUGMENTATION_STEPS+1)\n",
    "        for shift in len(list(product(aug_iter, aug_iter, aug_iter))):\n",
    "            \n",
    "            center_i = center + np.array(shift)\n",
    "            \n",
    "            info_patch['patch_center'] = center_i\n",
    "            info_patch['patient_number'] = k\n",
    "            info_patch['is_fcd'] = 1\n",
    "            \n",
    "        x_c, y_c, z_c = center\n",
    "        mask_tensor[x_c-pad:x_c+pad, y_c-pad:y_c+pad, z_c-pad:z_c+pad] = False\n",
    "        \n",
    "        ###################################\n",
    "        # CREATE RELEVANT non-FCD INDEXES #\n",
    "        ###################################\n",
    "        \n",
    "        xyz_grid = np.stack(np.meshgrid(np.arange(X), np.arange(Y), np.arange(Z), indexing='ij'), -1)\n",
    "        xyz_grid = xyz_grid[mask_tensor]\n",
    "\n",
    "        indexes_selected = Parallel(n_jobs=N_CPU//2)(delayed(check_patch)(x,y,z,\\\n",
    "                                                                            mask_tensor,\\\n",
    "                                                                            label_tensor,\\\n",
    "                                                                            patch_size) \\\n",
    "                                                               for x,y,z in xyz_grid)\n",
    "\n",
    "        indexes_selected = list(filter(lambda x: x is not None, indexes_selected))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
