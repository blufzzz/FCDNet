{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3dad70-ec93-401d-b544-a4271b89582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import re, time, os, shutil, json, math\n",
    "import numpy as np\n",
    "import configdot\n",
    "from tqdm import tqdm\n",
    "import monai\n",
    "from monai.data import DataLoader, Dataset, list_data_collate, decollate_batch\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn import plotting\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython.core.debugger import set_trace\n",
    "import pandas as pd\n",
    "from nibabel.freesurfer.io import read_morph_data\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n",
    "import torch.optim as optim\n",
    "from models.v2v import V2VModel\n",
    "\n",
    "from losses import *\n",
    "from dataset import setup_dataloaders, create_datafile, setup_datafiles, setup_transformations\n",
    "from utils import save, get_capacity, calc_gradient_norm, get_label, get_latest_weights\n",
    "\n",
    "\n",
    "from metrics import calculate_metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d1a03-4650-4b54-8ebb-4628826daf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "SEED = 42\n",
    "USE_nG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d64d2-a300-4042-ac20-ff45e2640b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = '/workspace/RawData/FCDNet/logs'\n",
    "\"\"\"\n",
    "log_dir_iter = ['stash/t1_all/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASK-to-all-imgch-t1-all_scaler-trial4@29.07.2022-11',\n",
    "                'stash/t1_cr-flair/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASK-to-all-imgch-t1-cr-flair_scaler-trial4@19.07.2022-09',\n",
    "                'stash/t1_blurring-flair/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASK-to-all-imgch-t1-blurring-flair_scaler-trial3@18.07.2022-10',\n",
    "                'stash/t1_entropy/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASK-to-all-imgch-t1-entropy_scaler-trial5@24.07.2022-08',\n",
    "                'stash/t1_blurring-t2/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASK-to-all-imgch-t1-blurring-t2_scaler-trial2@25.07.2022-07',\n",
    "                'stash/t1_blurring-t1/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASK-to-all-imgch-t1-blurring-t1_scaler-trial3@17.07.2022-15',\n",
    "                'stash/t1_variance/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASK-to-all-imgch-t1-variance_scaler-trial3@22.07.2022-10',\n",
    "                'stash/t1_sulc/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASK-to-all-imgch-t1-sulc_scaler-rerun_trail4@10.08.2022-20',\n",
    "                'stash/t1_thickness/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASK-to-all-imgch-t1-thickness_scaler-trial1@19.07.2022-09',\n",
    "                'stash/t1_curv/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASKint-t1-curv_scaler-trial3@22.08.2022-16']\n",
    "\"\"\"\n",
    "log_dir_iter = ['debug/loss/v2v-IN_autocast_TL-d-0.9_lr-1e-3_nG-bs2-AUG-MASKint-t1-all_scaler_minmax-prep@30.09.2022-14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79043d1e-9af2-4418-84c1-273f4c67cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean, median\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "\n",
    "DEVICE = 'cuda:1' # 'cuda:1' #'' # 'cpu'\n",
    "device = torch.device(DEVICE)\n",
    "test_files = None\n",
    "fold_metrics = OrderedDict()\n",
    "df_per_subj = pd.DataFrame(columns=['Feature','Label', 'Precision', 'Sensitivity', 'Specificity', 'Dice', 'Accuracy'])\n",
    "fold_file = './metadata/metadata_fcd_nG.npy'\n",
    "for i, logname in enumerate(log_dir_iter):\n",
    "    logdir = os.path.join(LOGDIR, logname)\n",
    "    config = configdot.parse_config(os.path.join(logdir,'config.ini'))\n",
    "    assert config.opt.val_batch_size == 1\n",
    "    assert config.model.name == \"v2v\"\n",
    "    \n",
    "    fold_index = logname.split('/')[2]  # feature name\n",
    "    \n",
    "    best_model = V2VModel(config).to(device)\n",
    "    model_dict = torch.load(get_latest_weights(logdir), map_location=DEVICE)\n",
    "    best_model.load_state_dict(model_dict['model_state'])\n",
    "    best_model.eval()\n",
    "    fold_npy = np.load(os.path.join(fold_file), allow_pickle=True).item()\n",
    "    print(fold_index)\n",
    "    test_list = fold_npy.get('test')\n",
    "    feat_params = config.dataset.features\n",
    "    test_files = create_datafile(test_list, feat_params, mask=True)\n",
    "    \n",
    "    _, val_trans =  setup_transformations(config)\n",
    "    test_ds = monai.data.Dataset(data=test_files[0], transform=val_trans)\n",
    "    test_loader = DataLoader(test_ds, \n",
    "                        batch_size=1, \n",
    "                        num_workers=0, \n",
    "                        collate_fn=list_data_collate,\n",
    "                        shuffle=False # important not to shuffle, to ensure label correspondence\n",
    "                        )\n",
    "    print(f'Start evaluate fold {fold_index}')\n",
    "    print(logdir)\n",
    "    dataloader = test_loader\n",
    "\n",
    "    brains = {}\n",
    "    labels_gt = {}\n",
    "    metric_dict = defaultdict(list)\n",
    "    label_pred_arr = {}\n",
    "    label_gt_arr = {}\n",
    "\n",
    "    metric = defaultdict()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # bs = 1\n",
    "        # brain_tensor - [1,C,H,W,D]\n",
    "        # mask_tensor - [1,1,H,W,D]\n",
    "        # label_tensor - [1,1,H,W,D]\n",
    "\n",
    "        #######################\n",
    "        # ITERATE OVER BRAINS #\n",
    "        #######################\n",
    "        iterator = enumerate(dataloader)\n",
    "\n",
    "\n",
    "        for iter_i, data_tensors in iterator:\n",
    "            brain_tensor, label_tensor, mask_tensor = (\n",
    "                                                      data_tensors['image'].to(device),\n",
    "                                                      data_tensors['seg'].to(device),\n",
    "                                                      data_tensors['mask'].to(device)\n",
    "                                                      )\n",
    "\n",
    "            label = get_label(dataloader.dataset.data[iter_i]['seg'])\n",
    "            print(f'Label: {label}')\n",
    "\n",
    "            # forward pass\n",
    "            label_tensor_forward = best_model(brain_tensor) # -> [1,1,ps,ps,ps]\n",
    "            label_tensor_predicted = label_tensor_forward.to(device)\n",
    "            label_tensor_predicted *= mask_tensor\n",
    "            brains[label] = brain_tensor[0,0].detach().cpu().numpy()\n",
    "            label_pred_arr[label] = label_tensor_predicted[0,0].detach().cpu().numpy()\n",
    "            label_gt_arr[label] = label_tensor[0,0].detach().cpu().numpy()\n",
    "            Precision, Sensitivity, Specificity, Dice, intensity, Accuracy = calculate_metrics(label_pred_arr[label], label_gt_arr[label])\n",
    "            df_per_subj = df_per_subj.append(pd.Series([fold_index, label, Precision, Sensitivity, Specificity, Dice, Accuracy], index=df_per_subj.columns), ignore_index=True)\n",
    "            metric[label] = [Precision, Sensitivity, Specificity, Dice, Accuracy]\n",
    "            \n",
    "            \n",
    "           \n",
    "            #intensity = 0.001\n",
    "            masked_labels_pred = np.ma.masked_where(label_pred_arr[label] < intensity, label_pred_arr[label])\n",
    "            masked_labels_gt = np.ma.masked_where(label_gt_arr[label] < intensity, label_gt_arr[label])\n",
    "            \n",
    "            '''\n",
    "            fig = figure(figsize=(12, 5), dpi=100)\n",
    "            #brain_pred = plotting.plot_anat(nib.Nifti1Image(masked_labels_pred, np.eye(4)), bg_img=nib.Nifti1Image(brains[label], np.eye(4)), cut_coords=(4,4,4), cmap='rainbow', alpha=0.5, display_mode='mosaic')\n",
    "            coord =  nilearn.plotting.find_cuts.find_xyz_cut_coords(nib.Nifti1Image(np.where(masked_labels_gt > 0.5,1,0), np.eye(4)))\n",
    "            brain_pred = plotting.plot_anat(nib.Nifti1Image(masked_labels_pred, np.eye(4)),\n",
    "                                                        bg_img=nib.Nifti1Image(brains[label], np.eye(4)),\n",
    "                                                        cmap='jet',\n",
    "                                                        alpha=0.4,\n",
    "                                                        figure=fig,\n",
    "                                                        draw_cross=False,\n",
    "                                                        black_bg=False,\n",
    "                                                        title=f'Subject {label}',\n",
    "                                                        colorbar=True,\n",
    "                                                        cut_coords=coord)\n",
    "            brain_pred.add_contours(nib.Nifti1Image(np.where(masked_labels_gt > 0.5,1,0), np.eye(4)), colors='b', levels=[1.0])\n",
    "            plt.show()\n",
    "            '''\n",
    "        \n",
    "            # if iter_i == 1:\n",
    "            #     break\n",
    "        # fold_metrics[str(fold_index)] = metric\n",
    "        \n",
    "        Prec = []\n",
    "        Sens = []\n",
    "        Spec = []\n",
    "        Dcs = []\n",
    "        Acrs = []\n",
    "        for j in metric:\n",
    "            #print(metric[i])\n",
    "            Prec.append(metric[j][0])\n",
    "            Sens.append(metric[j][1])\n",
    "            Spec.append(metric[j][2])\n",
    "            Dcs.append(metric[j][3])\n",
    "            Acrs.append(metric[j][4])\n",
    "        \n",
    "        print(f'Precision mean on fold {fold_index}:         {mean(Prec)}')\n",
    "        print(f'Sensitivity mean on fold {fold_index}:       {mean(Sens)}')\n",
    "        print(f'Specificity mean on on fold {fold_index}:    {mean(Spec)}')\n",
    "        print(f'Dice mean on fold {fold_index}:              {mean(Dcs)}')\n",
    "        print(f'Dice median on fold {fold_index}:            {median(Dcs)}')\n",
    "        print(f'Accuracy mean on fold {fold_index}:          {mean(Acrs)}')\n",
    "    # if i == 1:\n",
    "    #     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5fd86-c022-4f4c-b8b1-93b5f12e258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ef3db-7fe2-4d3b-b954-20a449576954",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_per_subj.set_index(['Feature', 'Label'])\n",
    "new_df.index = new_df.index.get_level_values(0)\n",
    "\"\"\"\n",
    "Filter_df  = new_df[new_df.index.isin(['t1_all',\n",
    "                                       't1_cr-flair',\n",
    "                                       't1_blurring-flair',\n",
    "                                       't1_entropy',\n",
    "                                       't1_cr-t2',\n",
    "                                       't1_blurring-t2',\n",
    "                                       't1_blurring-t1',\n",
    "                                       't1_variance',\n",
    "                                       't1_sulc',\n",
    "                                       't1_thickness',\n",
    "                                       't1_curv',\n",
    "                                       't1_cr-t2'])]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c61a8-f48e-42f2-8089-979a6837a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc62c3-80a6-4ac5-9390-5083419f131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "metric_df = Filter_df.copy()\n",
    "metric_df['pred'] = np.where(metric_df['Precision'] > 0.01, 1, 0)\n",
    "metric_df['gt'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc725ada-188c-42c5-82b4-243aa20cfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_l = ['t1_cr-flair',\n",
    "          't1_blurring-flair',\n",
    "          't1_entropy',\n",
    "          't1_cr-t2',\n",
    "          't1_blurring-t2',\n",
    "          't1_blurring-t1',\n",
    "          't1_variance',\n",
    "          't1_sulc',\n",
    "          't1_thickness',\n",
    "          't1_curv',\n",
    "          't1_cr-t2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689fc8f-0219-4d53-9691-bfe376140cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "prec = []\n",
    "sens = []\n",
    "spec = []\n",
    "dscs = []\n",
    "acry = []\n",
    "\n",
    "mean_mean_prec = []\n",
    "mean_mean_sens = []\n",
    "mean_mean_spec = []\n",
    "mean_mean_dscs = []\n",
    "mean_mean_acrs = []\n",
    "\n",
    "\n",
    "for fold in fold_l:\n",
    "    fold_pandas = metric_df[metric_df.index.isin([fold])]\n",
    "    mean_prec = np.mean(fold_pandas['Precision'].to_numpy())\n",
    "    mean_sens = np.mean(fold_pandas['Sensitivity'].to_numpy())\n",
    "    mean_spec = np.mean(fold_pandas['Specificity'].to_numpy())\n",
    "    mean_dscs = np.mean(fold_pandas['Dice'].to_numpy())\n",
    "    mean_acrs = np.mean(fold_pandas['Accuracy'].to_numpy())\n",
    "    \n",
    "    mean_mean_prec.append(mean_prec)\n",
    "    mean_mean_sens.append(mean_sens)\n",
    "    mean_mean_spec.append(mean_spec)\n",
    "    mean_mean_dscs.append(mean_dscs)\n",
    "    mean_mean_acrs.append(mean_acrs)\n",
    "    \n",
    "    print(\n",
    "          f'Fold                  {fold}\\n'\n",
    "          f'Precision:            {mean_prec}\\n',\n",
    "          f'Sensitivity:          {mean_sens}\\n',\n",
    "          f'Specificity:          {mean_spec}\\n',\n",
    "          f'Dice:                 {mean_dscs}\\n',\n",
    "          f'Accuracy:             {mean_acrs}\\n'\n",
    "         )\n",
    "    \n",
    "    \"\"\"\n",
    "    pred = fold_pandas['pred'].to_numpy()\n",
    "    gt = fold_pandas['gt'].to_numpy()\n",
    "    tn, fp, fn, tp = confusion_matrix(gt, pred).ravel()\n",
    "    precision = tp/(tp+fp)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    dice = 2*tp/(2*tp+fp+fn)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    print(\n",
    "          f'Fold                  {fold}\\n'\n",
    "          f'Precision:            {precision}\\n',\n",
    "          f'Sensitivity:          {sensitivity}\\n',\n",
    "          f'Specificity:          {specificity}\\n',\n",
    "          f'Dice:                 {dice}\\n',\n",
    "          f'Accuracy:             {accuracy}\\n'\n",
    "         )\n",
    "    \n",
    "    prec.append(precision)\n",
    "    sens.append(sensitivity)\n",
    "    spec.append(specificity)\n",
    "    dscs.append(dice)\n",
    "    acry.append(accuracy)\n",
    "    \n",
    "\n",
    "print('Patient Level\\n'\n",
    "      f'Mean Precision:            {mean(prec)}\\n',\n",
    "      f'Mean Sensitivity:          {mean(sens)}\\n',\n",
    "      f'Mean Specificity:          {mean(spec)}\\n',\n",
    "      f'Mean Dice:                 {mean(dscs)}\\n',\n",
    "      f'Mean Accuracy:             {mean(acry)}\\n'\n",
    "     )\n",
    "\"\"\"\n",
    "print('Voxel-wise Level\\n'\n",
    "      f'Mean Precision:            {mean(mean_mean_prec)}\\n',\n",
    "      f'Mean Sensitivity:          {mean(mean_mean_sens)}\\n',\n",
    "      f'Mean Specificity:          {mean(mean_mean_spec)}\\n',\n",
    "      f'Mean Dice:                 {mean(mean_mean_dscs)}\\n',\n",
    "      f'Mean Accuracy:             {mean(mean_mean_acrs)}\\n'\n",
    "     )\n",
    "    \n",
    "#cm = confusion_matrix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326c372-cfa1-41f9-bb6b-c3be0255b887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
