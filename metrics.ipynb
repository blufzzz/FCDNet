{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4653b04-2edc-41a5-accc-70737b7bfaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "\n",
    "import re, time, os, shutil, json, math\n",
    "import numpy as np\n",
    "import configdot\n",
    "from tqdm import tqdm\n",
    "import monai\n",
    "from monai.data import DataLoader, Dataset, list_data_collate, decollate_batch\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn import plotting\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython.core.debugger import set_trace\n",
    "import pandas as pd\n",
    "from nibabel.freesurfer.io import read_morph_data\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n",
    "import torch.optim as optim\n",
    "from models.v2v import V2VModel\n",
    "\n",
    "from losses import *\n",
    "from dataset import setup_dataloaders, create_datafile, setup_datafiles, setup_transformations\n",
    "from utils import save, get_capacity, calc_gradient_norm, get_label, get_latest_weights\n",
    "\n",
    "\n",
    "from metrics import calculate_metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9196b2-96e1-4460-8acc-db508eb621f4",
   "metadata": {},
   "source": [
    "### Get test data without nG indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb11b4a-0203-4be6-b27d-f4f1ba6692dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17734541272635785841\n",
      "6246303251675928261\n",
      "10229961000563817043\n",
      "13972218761186368727\n",
      "13655251993840457457\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(132)\n",
    "for i in range(5):\n",
    "    print(torch.seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da3f078-1d5c-4df7-9273-bbb48e47692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "SEED = 42\n",
    "USE_nG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ebf055-d514-4a9c-a0e5-67968d89677c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_list = np.load('./metadata/metadata_fcd_noind.npy', allow_pickle=True).item()\n",
    "test_list = test_list.get('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801b64d-7532-47d6-a253-f893177df510",
   "metadata": {},
   "source": [
    "### Get val data with nG indexes for forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94564d68-dd48-4351-9e05-257df386ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset = np.load('./metadata/metadata_fcd_nG.npy',allow_pickle=True).item()\n",
    "val_subj_indcs = meta_dataset.get('test')\n",
    "val_subj_indcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a3c55-2144-47fa-9a27-0bf4b875ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = '/workspace/RawData/FCDNet/logs/cross_validation_all/t1_cv'\n",
    "log_dir_iter = os.listdir(LOGDIR)\n",
    "log_dir_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32626da6-10a8-4f9c-8224-a93959854927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "LOGDIR2 = '/workspace/RawData/FCDNet/logs/features_comparison'\n",
    "\n",
    "iter_dir = ['t1',\n",
    " 't1_all',\n",
    " 't1_blurring-flair',\n",
    " 't1_blurring-t1',\n",
    " 't1_blurring-t2',\n",
    " 't1_cr-flair',\n",
    " 't1_cr-t2',\n",
    " 't1_curv',\n",
    " 't1_entropy',\n",
    " 't1_sulc',\n",
    " 't1_thickness',\n",
    " 't1_variance']\n",
    "\n",
    "for dire in iter_dir:\n",
    "    iter_l = os.path.join(LOGDIR2, dire)\n",
    "    exp_l = os.listdir(iter_l)\n",
    "    print('---------------------------------------')\n",
    "    print(f'Checking {dire}...')\n",
    "    print('---------------------------------------')\n",
    "    for exp in exp_l:\n",
    "        if 'v2v' in exp:\n",
    "            trual_num = exp.split('@')[0][-1]\n",
    "            # path of the \n",
    "            full_path_checkp = os.path.join(iter_l, exp, 'checkpoints')\n",
    "            checkpoints_names = os.listdir(full_path_checkp)\n",
    "            if os.path.exists(full_path_checkp) and len(checkpoints_names) > 0:\n",
    "                checkpoints_names = sorted(checkpoints_names, key=lambda x: int(re.findall('\\d+', x)[0]))\n",
    "                checkpoint = checkpoints_names[-1]\n",
    "                print(f'Chekpoint {checkpoint} found! for {dire} in trial: {trual_num}')\n",
    "            else:\n",
    "                print(f'No checkpoints for {dire} in trial {trual_num}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871993cf-a326-4dbe-9901-c9a81d679217",
   "metadata": {},
   "outputs": [],
   "source": [
    "logname = log_dir_iter[0]\n",
    "logdir = os.path.join(LOGDIR, logname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a1a3b-66d0-4595-8cfe-5c51dacf4f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = configdot.parse_config(os.path.join(logdir,'config-cv.ini'))\n",
    "assert config.opt.val_batch_size == 1\n",
    "DEVICE = 'cuda:0' # 'cuda:1' #'' # 'cpu'\n",
    "device = torch.device(DEVICE)\n",
    "\n",
    "#########\n",
    "# MODEL #\n",
    "#########\n",
    "assert config.model.name == \"v2v\"\n",
    "best_model = V2VModel(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80edbee-63d2-4d51-860a-8b260eaaf51a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dict = torch.load(get_latest_weights(logdir), map_location=DEVICE)\n",
    "best_model.load_state_dict(model_dict['model_state'])\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7456c2-b3e8-4fd1-9f0e-d0d4e1aec68c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader = setup_dataloaders(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2003bb51-aad9-436b-b614-77d76ab87aec",
   "metadata": {},
   "source": [
    "### Plot validation set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24389518-576d-4f82-bd82-6639b372dc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = val_loader\n",
    "\n",
    "brains = {}\n",
    "labels_gt = {}\n",
    "metric_dict = defaultdict(list)\n",
    "label_pred_arr = {}\n",
    "label_gt_arr = {}\n",
    "\n",
    "metric = defaultdict()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # bs = 1\n",
    "    # brain_tensor - [1,C,H,W,D]\n",
    "    # mask_tensor - [1,1,H,W,D]\n",
    "    # label_tensor - [1,1,H,W,D]\n",
    "    \n",
    "    #######################\n",
    "    # ITERATE OVER BRAINS #\n",
    "    #######################\n",
    "    iterator = enumerate(dataloader)\n",
    "   \n",
    "    \n",
    "    for iter_i, data_tensors in tqdm(iterator):\n",
    "        brain_tensor, label_tensor, mask_tensor = (\n",
    "                                                  data_tensors['image'].to(device),\n",
    "                                                  data_tensors['seg'].to(device),\n",
    "                                                  data_tensors['mask'].to(device)\n",
    "                                                  )\n",
    "\n",
    "        label = get_label(dataloader.dataset.data[iter_i]['seg'])\n",
    "        print(f'Label: {label}')\n",
    "        \n",
    "        # forward pass\n",
    "        label_tensor_forward = best_model(brain_tensor) # -> [1,1,ps,ps,ps]\n",
    "        label_tensor_predicted = label_tensor_forward.to(device)\n",
    "        label_tensor_predicted *= mask_tensor\n",
    "        brains[label] = brain_tensor[0,0].detach().cpu().numpy()\n",
    "        label_pred_arr[label] = label_tensor_predicted[0,0].detach().cpu().numpy()\n",
    "        label_gt_arr[label] = label_tensor[0,0].detach().cpu().numpy()\n",
    "        \n",
    "        Precision, Sensitivity, Specificity, Dice, intensity,_ = calculate_metrics(label_pred_arr[label], label_gt_arr[label])\n",
    "        print(label,'\\n', f'Dice {Dice}\\n', f'Precicion {Precision}\\n', f'Sensitivity {Sensitivity}\\n', f'Specificity {Specificity}')\n",
    "        print(f'Threshold {intensity}')\n",
    "        metric[label] = [Precision, Sensitivity, Specificity, Dice, intensity]\n",
    "        \n",
    "        #plt.figure(\"image\", (30, 10))\n",
    "        fig = figure(figsize=(12, 5), dpi=100)\n",
    "        intensity = 0.001\n",
    "        \n",
    "        # Plot with intensities thresholded by calculate_metrics function\n",
    "        masked_labels_pred = np.ma.masked_where(label_pred_arr[label] < intensity, label_pred_arr[label])\n",
    "        masked_labels_gt = np.ma.masked_where(label_gt_arr[label] < intensity, label_gt_arr[label])\n",
    "        #brain_pred = plotting.plot_anat(nib.Nifti1Image(masked_labels_pred, np.eye(4)), bg_img=nib.Nifti1Image(brains[label], np.eye(4)), cut_coords=(4,4,4), cmap='rainbow', alpha=0.5, display_mode='mosaic')\n",
    "        brain_pred = plotting.plot_anat(nib.Nifti1Image(masked_labels_pred, np.eye(4)),\n",
    "                                                        bg_img=nib.Nifti1Image(brains[label], np.eye(4)),\n",
    "                                                        cmap='jet',\n",
    "                                                        alpha=0.4,\n",
    "                                                        figure=fig,\n",
    "                                                        draw_cross=False,\n",
    "                                                        black_bg=False,\n",
    "                                                        title=f'Subject {label}',\n",
    "                                                        colorbar=True,)\n",
    "        brain_pred.add_contours(nib.Nifti1Image(np.where(masked_labels_gt > 0.5,1,0), np.eye(4)), colors='b', levels=[1.0])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2622e-e3aa-4f6c-958d-9d8d904af8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subj_num = 10\n",
    "de_prec = 0\n",
    "\n",
    "for number in metric.values():\n",
    "    #print(number[0])\n",
    "    if number[0] > 0.1:\n",
    "        de_prec += 1\n",
    "print(de_prec / val_subj_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b862e19-74a0-4a87-b0ae-1f98259e1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "Precision = []\n",
    "Sensitivity = []\n",
    "Specificity = []\n",
    "Dice = []\n",
    "\n",
    "for i in metric:\n",
    "    #print(metric[i])\n",
    "    Precision.append(metric[i][0])\n",
    "    Sensitivity.append(metric[i][1])\n",
    "    Specificity.append(metric[i][2])\n",
    "    Dice.append(metric[i][3])\n",
    "     \n",
    "print(f'Precision mean on validation:      {mean(Precision)}')\n",
    "print(f'Sensitivity mean on validation:    {mean(Sensitivity)}')\n",
    "print(f'Specificity mean on validation:    {mean(Specificity)}')\n",
    "print(f'Dice on validation                 {mean(Dice)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba8c0d-9d2f-49f2-90e8-a48a5384cc91",
   "metadata": {},
   "source": [
    "### Plot Cross-validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4e74f-b1cc-4385-8744-41f2b556659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = '/workspace/RawData/FCDNet/logs/cross_validation_all/t1_all_cv'\n",
    "log_dir_iter = os.listdir(LOGDIR)\n",
    "log_dir_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171cac12-c85f-4167-ac83-596af466fdce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statistics import mean, median\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "\n",
    "DEVICE = 'cuda:1' # 'cuda:1' #'' # 'cpu'\n",
    "device = torch.device(DEVICE)\n",
    "test_files = None\n",
    "fold_metrics = OrderedDict()\n",
    "df_per_subj = pd.DataFrame(columns=['Fold','Label', 'Precision', 'Sensitivity', 'Specificity', 'Dice', 'Accuracy'])\n",
    "\n",
    "for i, logname in enumerate(log_dir_iter):\n",
    "    logdir = os.path.join(LOGDIR, logname)\n",
    "    config = configdot.parse_config(os.path.join(logdir,'config-cv.ini'))\n",
    "    assert config.opt.val_batch_size == 1\n",
    "    assert config.model.name == \"v2v\"\n",
    "    fold_file = [filename for filename in os.listdir(logdir) if re.match(r\"^dataset-fold.*.npy\", filename)]\n",
    "    fold_index = fold_file[0].split('-')[2].split('.')[0]\n",
    "    best_model = V2VModel(config).to(device)\n",
    "    model_dict = torch.load(get_latest_weights(logdir))\n",
    "    best_model.load_state_dict(model_dict['model_state'])\n",
    "    best_model.eval()\n",
    "    fold_npy = np.load(os.path.join(logdir, fold_file[0]), allow_pickle=True).item()\n",
    "    test_list = fold_npy.get('val')\n",
    "    feat_params = config.dataset.features\n",
    "    test_files = create_datafile(test_list, feat_params, mask=True)\n",
    "    \n",
    "    _, val_trans =  setup_transformations(config)\n",
    "    test_ds = monai.data.Dataset(data=test_files[0], transform=val_trans)\n",
    "    test_loader = DataLoader(test_ds, \n",
    "                        batch_size=1, \n",
    "                        num_workers=0, \n",
    "                        collate_fn=list_data_collate,\n",
    "                        shuffle=False # important not to shuffle, to ensure label correspondence\n",
    "                        )\n",
    "    print(f'Start evaluate fold {fold_file[0]}')\n",
    "    print(logdir)\n",
    "    dataloader = test_loader\n",
    "\n",
    "    brains = {}\n",
    "    labels_gt = {}\n",
    "    metric_dict = defaultdict(list)\n",
    "    label_pred_arr = {}\n",
    "    label_gt_arr = {}\n",
    "\n",
    "    metric = defaultdict()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # bs = 1\n",
    "        # brain_tensor - [1,C,H,W,D]\n",
    "        # mask_tensor - [1,1,H,W,D]\n",
    "        # label_tensor - [1,1,H,W,D]\n",
    "\n",
    "        #######################\n",
    "        # ITERATE OVER BRAINS #\n",
    "        #######################\n",
    "        iterator = enumerate(dataloader)\n",
    "\n",
    "\n",
    "        for iter_i, data_tensors in iterator:\n",
    "            brain_tensor, label_tensor, mask_tensor = (\n",
    "                                                      data_tensors['image'].to(device),\n",
    "                                                      data_tensors['seg'].to(device),\n",
    "                                                      data_tensors['mask'].to(device)\n",
    "                                                      )\n",
    "\n",
    "            label = get_label(dataloader.dataset.data[iter_i]['seg'])\n",
    "            print(f'Label: {label}')\n",
    "\n",
    "            # forward pass\n",
    "            label_tensor_forward = best_model(brain_tensor) # -> [1,1,ps,ps,ps]\n",
    "            label_tensor_predicted = label_tensor_forward.to(device)\n",
    "            label_tensor_predicted *= mask_tensor\n",
    "            brains[label] = brain_tensor[0,0].detach().cpu().numpy()\n",
    "            label_pred_arr[label] = label_tensor_predicted[0,0].detach().cpu().numpy()\n",
    "            label_gt_arr[label] = label_tensor[0,0].detach().cpu().numpy()\n",
    "            Precision, Sensitivity, Specificity, Dice, intensity, Accuracy = calculate_metrics(label_pred_arr[label], label_gt_arr[label])\n",
    "            df_per_subj = df_per_subj.append(pd.Series([fold_index, label, Precision, Sensitivity, Specificity, Dice, Accuracy], index=df_per_subj.columns), ignore_index=True)\n",
    "            metric[label] = [Precision, Sensitivity, Specificity, Dice, Accuracy]\n",
    "            \n",
    "            \n",
    "           \n",
    "            #intensity = 0.001\n",
    "            masked_labels_pred = np.ma.masked_where(label_pred_arr[label] < intensity, label_pred_arr[label])\n",
    "            masked_labels_gt = np.ma.masked_where(label_gt_arr[label] < intensity, label_gt_arr[label])\n",
    "            \"\"\"\n",
    "            fig = figure(figsize=(12, 5), dpi=100)\n",
    "            #brain_pred = plotting.plot_anat(nib.Nifti1Image(masked_labels_pred, np.eye(4)), bg_img=nib.Nifti1Image(brains[label], np.eye(4)), cut_coords=(4,4,4), cmap='rainbow', alpha=0.5, display_mode='mosaic')\n",
    "            coord =  nilearn.plotting.find_cuts.find_xyz_cut_coords(nib.Nifti1Image(np.where(masked_labels_gt > 0.5,1,0), np.eye(4)))\n",
    "            brain_pred = plotting.plot_anat(nib.Nifti1Image(masked_labels_pred, np.eye(4)),\n",
    "                                                        bg_img=nib.Nifti1Image(brains[label], np.eye(4)),\n",
    "                                                        cmap='jet',\n",
    "                                                        alpha=0.4,\n",
    "                                                        figure=fig,\n",
    "                                                        draw_cross=False,\n",
    "                                                        black_bg=False,\n",
    "                                                        title=f'Subject {label}',\n",
    "                                                        colorbar=True,\n",
    "                                                        cut_coords=coord)\n",
    "            brain_pred.add_contours(nib.Nifti1Image(np.where(masked_labels_gt > 0.5,1,0), np.eye(4)), colors='b', levels=[1.0])\n",
    "            plt.show()\n",
    "            \"\"\"\n",
    "            # if iter_i == 1:\n",
    "            #     break\n",
    "        # fold_metrics[str(fold_index)] = metric\n",
    "        \n",
    "        Prec = []\n",
    "        Sens = []\n",
    "        Spec = []\n",
    "        Dcs = []\n",
    "        Acrs = []\n",
    "        for j in metric:\n",
    "            #print(metric[i])\n",
    "            Prec.append(metric[j][0])\n",
    "            Sens.append(metric[j][1])\n",
    "            Spec.append(metric[j][2])\n",
    "            Dcs.append(metric[j][3])\n",
    "            Acrs.append(metric[j][4])\n",
    "        \n",
    "        print(f'Precision mean on fold {fold_file[0]}:         {mean(Prec)}')\n",
    "        print(f'Sensitivity mean on fold {fold_file[0]}:       {mean(Sens)}')\n",
    "        print(f'Specificity mean on on fold {fold_file[0]}:    {mean(Spec)}')\n",
    "        print(f'Dice mean on fold {fold_file[0]}:              {mean(Dcs)}')\n",
    "        print(f'Dice median on fold {fold_file[0]}:            {median(Dcs)}')\n",
    "        print(f'Accuracy mean on fold {fold_file[0]}:          {mean(Acrs)}')\n",
    "        \n",
    "        \n",
    "    # if i == 1:\n",
    "    #     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06756c09-586c-4a9c-aaae-4368cbcfa727",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_per_subj.set_index(['Fold', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c614e053-2398-41ff-a187-1838011127b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.index = new_df.index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc7debc-0b46-4e6a-b88a-df92db2085ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filter_df  = new_df[new_df.index.isin(['0','1','2','3','4', '5', '6', '7','8'])].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4d679-3b7e-4280-8f5b-2b9d42cf2ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd505df-db76-4f21-a2ae-38c5bb7ce3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "metric_df = Filter_df.copy()\n",
    "metric_df['pred'] = np.where(metric_df['Precision'] > 0.01, 1, 0)\n",
    "metric_df['gt'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e24b45-adf0-4c70-8263-16cddfba2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "prec = []\n",
    "sens = []\n",
    "spec = []\n",
    "dscs = []\n",
    "acry = []\n",
    "\n",
    "mean_mean_prec = []\n",
    "mean_mean_sens = []\n",
    "mean_mean_spec = []\n",
    "mean_mean_dscs = []\n",
    "mean_mean_acrs = []\n",
    "\n",
    "\n",
    "for fold in range(0,9):\n",
    "    fold_pandas = metric_df[metric_df.index.isin([str(fold)])]\n",
    "    mean_prec = np.mean(fold_pandas['Precision'].to_numpy())\n",
    "    mean_sens = np.mean(fold_pandas['Sensitivity'].to_numpy())\n",
    "    mean_spec = np.mean(fold_pandas['Specificity'].to_numpy())\n",
    "    mean_dscs = np.mean(fold_pandas['Dice'].to_numpy())\n",
    "    mean_acrs = np.mean(fold_pandas['Accuracy'].to_numpy())\n",
    "    \n",
    "    mean_mean_prec.append(mean_prec)\n",
    "    mean_mean_sens.append(mean_sens)\n",
    "    mean_mean_spec.append(mean_spec)\n",
    "    mean_mean_dscs.append(mean_dscs)\n",
    "    mean_mean_acrs.append(mean_acrs)\n",
    "    \n",
    "    pred = fold_pandas['pred'].to_numpy()\n",
    "    gt = fold_pandas['gt'].to_numpy()\n",
    "    tn, fp, fn, tp = confusion_matrix(gt, pred).ravel()\n",
    "    precision = tp/(tp+fp)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    dice = 2*tp/(2*tp+fp+fn)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    print(\n",
    "          f'Fold                  {fold}\\n'\n",
    "          f'Precision:            {precision}\\n',\n",
    "          f'Sensitivity:          {sensitivity}\\n',\n",
    "          f'Specificity:          {specificity}\\n',\n",
    "          f'Dice:                 {dice}\\n',\n",
    "          f'Accuracy:             {accuracy}\\n'\n",
    "         )\n",
    "    \n",
    "    prec.append(precision)\n",
    "    sens.append(sensitivity)\n",
    "    spec.append(specificity)\n",
    "    dscs.append(dice)\n",
    "    acry.append(accuracy)\n",
    "    \n",
    "print('Patient Level\\n'\n",
    "      f'Mean Precision:            {mean(prec)}\\n',\n",
    "      f'Mean Sensitivity:          {mean(sens)}\\n',\n",
    "      f'Mean Specificity:          {mean(spec)}\\n',\n",
    "      f'Mean Dice:                 {mean(dscs)}\\n',\n",
    "      f'Mean Accuracy:             {mean(acry)}\\n'\n",
    "     )\n",
    "\n",
    "print('Voxel-wise Level\\n'\n",
    "      f'Mean Precision:            {mean(mean_mean_prec)}\\n',\n",
    "      f'Mean Sensitivity:          {mean(mean_mean_sens)}\\n',\n",
    "      f'Mean Specificity:          {mean(mean_mean_spec)}\\n',\n",
    "      f'Mean Dice:                 {mean(mean_mean_dscs)}\\n',\n",
    "      f'Mean Accuracy:             {mean(mean_mean_acrs)}\\n'\n",
    "     )\n",
    "    \n",
    "#cm = confusion_matrix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a257327-4581-4d0f-8165-3450883d3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = new_df.columns.values\n",
    "for metric in metric_names:\n",
    "    \n",
    "    #fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(4*5,5), dpi=200)\n",
    "\n",
    "    #sns.axes_style(\"darkgrid\")\n",
    "    #sns.set_context(\"notebook\", font_scale=2, rc={\"lines.linewidth\": 2.5, 'figure.figsize':(30,10)})\n",
    "\n",
    "    g = sns.boxplot(\n",
    "                    data=Filter_df,\n",
    "                    y=metric,\n",
    "                    x=Filter_df.index,\n",
    "                    showcaps=True,\n",
    "                    flierprops={\"marker\": \"x\"},\n",
    "                    boxprops={\"facecolor\": (.4, .6, .8, .5)},\n",
    "                    medianprops={\"color\": \"coral\"},\n",
    "                    showmeans=True\n",
    "                   )\n",
    "    \n",
    "    #g = sns.catplot(kind=\"box\", data=new_df, y=metric, x=Filter_df.index)\n",
    "    #g.fig.set_size_inches(15,5)\n",
    "    #g.fig.set_dpi(300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2769bb-f47c-447a-8309-3a27e3fa0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883cccb-d1c5-4725-b795-568428a48fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in fold_metrics.items():\n",
    "    for pat in v.items():\n",
    "        print(pat[1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901d329-6b05-4481-9996-87284f718310",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a488f-2f91-42d6-8f4f-ced8f7b6e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logname = log_dir_iter[1]\n",
    "logdir = os.path.join(LOGDIR, logname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb524bb-1a40-4658-8c09-ffd707262509",
   "metadata": {},
   "outputs": [],
   "source": [
    "logname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4066a26-4b88-4369-93fc-715c84d62f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configdot.parse_config(os.path.join(logdir,'config-cv.ini'))\n",
    "assert config.opt.val_batch_size == 1\n",
    "DEVICE = 'cuda:0' # 'cuda:1' #'' # 'cpu'\n",
    "device = torch.device(DEVICE)\n",
    "\n",
    "#########\n",
    "# MODEL #\n",
    "#########\n",
    "assert config.model.name == \"v2v\"\n",
    "best_model = V2VModel(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c941a-c147-48b5-aed3-d7abf6f857dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = np.load('./metadata/metadata_fcd_nG.npy', allow_pickle=True).item()\n",
    "test_list.get('test')\n",
    "nG_list = np.concatenate((test_list.get('test'),test_list.get('train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedbb4d4-d83c-4115-8538-5cd56d870e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = test_list.get('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e93dc-75b0-48ce-956a-e90f5c71b85c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_params = config.dataset.features\n",
    "test_files = create_datafile(test_list, feat_params, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffc618-a0eb-42c6-a5dc-c0aaa524f02d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(test_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349de16e-debd-4fe4-879e-17666aac3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_trans =  setup_transformations(config)\n",
    "test_ds = monai.data.Dataset(data=test_files[0], transform=val_trans)\n",
    "test_loader = DataLoader(test_ds, \n",
    "                        batch_size=1, \n",
    "                        num_workers=0, \n",
    "                        collate_fn=list_data_collate,\n",
    "                        shuffle=False # important not to shuffle, to ensure label correspondence\n",
    "                        )\n",
    "check_data = monai.utils.misc.first(test_loader)\n",
    "check_data['seg'].shape, check_data['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e7152-abf0-4c70-b510-93c52c575843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c655bd8-5d30-4f50-ad7d-2709704e69b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = test_loader\n",
    "\n",
    "brains = {}\n",
    "labels_gt = {}\n",
    "metric_dict = defaultdict(list)\n",
    "label_pred_arr = {}\n",
    "label_gt_arr = {}\n",
    "\n",
    "metric = defaultdict()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # bs = 1\n",
    "    # brain_tensor - [1,C,H,W,D]\n",
    "    # mask_tensor - [1,1,H,W,D]\n",
    "    # label_tensor - [1,1,H,W,D]\n",
    "    \n",
    "    #######################\n",
    "    # ITERATE OVER BRAINS #\n",
    "    #######################\n",
    "    iterator = enumerate(dataloader)\n",
    "   \n",
    "    \n",
    "    for iter_i, data_tensors in tqdm(iterator):\n",
    "        brain_tensor, label_tensor, mask_tensor = (\n",
    "                                                  data_tensors['image'].to(device),\n",
    "                                                  data_tensors['seg'].to(device),\n",
    "                                                  data_tensors['mask'].to(device)\n",
    "                                                  )\n",
    "\n",
    "        label = get_label(dataloader.dataset.data[iter_i]['seg'])\n",
    "        print(f'Label: {label}')\n",
    "        \n",
    "        # forward pass\n",
    "        label_tensor_forward = best_model(brain_tensor) # -> [1,1,ps,ps,ps]\n",
    "        label_tensor_predicted = label_tensor_forward.to(device)\n",
    "        label_tensor_predicted *= mask_tensor\n",
    "        brains[label] = brain_tensor[0,0].detach().cpu().numpy()\n",
    "        label_pred_arr[label] = label_tensor_predicted[0,0].detach().cpu().numpy()\n",
    "        label_gt_arr[label] = label_tensor[0,0].detach().cpu().numpy()\n",
    "        \n",
    "        Precision, Sensitivity, Specificity, Dice, intensity,_ = calculate_metrics(label_pred_arr[label], label_gt_arr[label])\n",
    "        print(label,'\\n', f'Dice {Dice}\\n', f'Precicion {Precision}\\n', f'Sensitivity {Sensitivity}\\n', f'Specificity {Specificity}')\n",
    "        print(f'Threshold {intensity}')\n",
    "        metric[label] = [Precision, Sensitivity, Specificity, Dice, intensity]\n",
    "        \n",
    "        #plt.figure(\"image\", (30, 10))\n",
    "        fig = figure(figsize=(12, 5), dpi=100)\n",
    "        intensity = 0.001\n",
    "        \n",
    "        # Plot with intensities thresholded by calculate_metrics function\n",
    "        masked_labels_pred = np.ma.masked_where(label_pred_arr[label] < intensity, label_pred_arr[label])\n",
    "        masked_labels_gt = np.ma.masked_where(label_gt_arr[label] < intensity, label_gt_arr[label])\n",
    "        \n",
    "        coords = nilearn.plotting.find_xyz_cut_coords(nib.Nifti1Image(label_gt_arr[label], np.eye(4)), mask_img=None, activation_threshold=None)\n",
    "        #brain_pred = plotting.plot_anat(nib.Nifti1Image(masked_labels_pred, np.eye(4)), bg_img=nib.Nifti1Image(brains[label], np.eye(4)), cut_coords=(4,4,4), cmap='rainbow', alpha=0.5, display_mode='mosaic')\n",
    "        brain_pred = plotting.plot_anat(nib.Nifti1Image(masked_labels_pred, np.eye(4)),\n",
    "                                                        bg_img=nib.Nifti1Image(brains[label], np.eye(4)),\n",
    "                                                        cmap='jet',\n",
    "                                                        alpha=0.4,\n",
    "                                                        figure=fig,\n",
    "                                                        draw_cross=False,\n",
    "                                                        black_bg=False,\n",
    "                                                        title=f'Subject {label}',\n",
    "                                                        cut_coords=coords,\n",
    "                                                        colorbar=True,)\n",
    "        brain_pred.add_contours(nib.Nifti1Image(np.where(masked_labels_gt > 0.5,1,0), np.eye(4)), colors='b', levels=[1.0])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674dc4d-8238-4f9a-8053-c4665efb9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subj_list = []\n",
    "val_part_1 = meta_dataset.get('test')\n",
    "val_part_2 = meta_dataset.get('train')\n",
    "test_npy = np.load('./metadata/metadata_fcd_noind.npy',allow_pickle=True).item()\n",
    "test_part = test_npy.get('test')\n",
    "#all_subj_list = val_part_1.tolist() + val_part_2.tolist() + test_part  # Take all dataset with all indexes\n",
    "\n",
    "nG_npy = np.load('./metadata/metadata_fcd_nG.npy',allow_pickle=True).item()\n",
    "all_subj_list = np.concatenate((nG_npy.get('test'), nG_npy.get('train')))\n",
    "\n",
    "all_subj_list = [s.upper() if s.endswith('ns') else s for s in all_subj_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb938c-5b2d-4365-a8c6-6b0eadef1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_subj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793de6ee-e049-4f3a-984f-a0fc769603ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_params = config.dataset.features\n",
    "all_subj_files = create_datafile(all_subj_list, feat_params, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0d71d-5a4b-4d24-a23e-be7310401d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_trans =  setup_transformations(config)\n",
    "all_subj_ds = monai.data.Dataset(data=all_subj_files[0], transform=val_trans)\n",
    "all_subj_loader = DataLoader(all_subj_ds, \n",
    "                        batch_size=1, \n",
    "                        num_workers=0, \n",
    "                        collate_fn=list_data_collate,\n",
    "                        shuffle=False # important not to shuffle, to ensure label correspondence\n",
    "                        )\n",
    "check_data = monai.utils.misc.first(all_subj_loader)\n",
    "check_data['seg'].shape, check_data['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88e500-d9e9-4871-9535-e0d7f489efef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "n_crops = 10\n",
    "metric = defaultdict()\n",
    "data_path = f'/workspace/RawData/v2vNet'\n",
    "subs_ = all_subj_list\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "fig, ax = plt.subplots(figsize=(25,17))\n",
    "detections_ = []\n",
    "detection_table = np.zeros((len(subs_), 10))\n",
    "for k,feature in enumerate(['v2v_t1-all_features']):\n",
    "#for feature in ['Blurring T1','Blurring T2','Thickness','Sulc','Curv']:\n",
    "    df_metric = pd.DataFrame(columns=['subject', 'x', 'y', 'z', 'average_prediction', 'label_size', 'intersection_size'])\n",
    "    n_of_subs = 0\n",
    "    for j,sub in enumerate(tqdm(subs_)):\n",
    "        prediction_path  = f'{data_path}/pred/{sub}.nii.gz'   \n",
    "        label_path = f'{data_path}/label/{sub}.nii.gz'\n",
    "        try:\n",
    "            prediction = nib.load(prediction_path)\n",
    "            prediction_data = prediction.get_fdata()\n",
    "            label = (nib.load(label_path).get_fdata()>0.1).astype('uint8')\n",
    "        except:\n",
    "            print(f'Cannot open {prediction_path}')\n",
    "            detection_table[j,k] = -1\n",
    "            continue\n",
    "        n_of_subs += 1\n",
    "        \"\"\"\n",
    "        crops_df = pd.DataFrame(columns=['subject', 'x', 'y', 'z', 'average_prediction', 'label_size', 'intersection_size'])\n",
    "        crop_size=np.array([12,12,12])#(np.array([64,64,64])/prediction.header.get_zooms()).astype(np.int64)\n",
    "        i = 0 \n",
    "        for x in range(0, prediction_data.shape[0]-crop_size[0]//2, crop_size[0]//2):\n",
    "            for y in range(0, prediction_data.shape[1]-crop_size[1]//2, crop_size[1]//2):\n",
    "                for z in range(0, prediction_data.shape[2]-crop_size[2]//2, crop_size[2]//2):\n",
    "\n",
    "                    crop_pred = prediction_data[x: min(x+crop_size[0], prediction.shape[0]),\n",
    "                                           y: min(y+crop_size[1], prediction.shape[1]),\n",
    "                                           z: min(z+crop_size[2], prediction.shape[2]),]\n",
    "                    crop_label = label[x: min(x+crop_size[0], prediction.shape[0]),\n",
    "                                       y: min(y+crop_size[1], prediction.shape[1]),\n",
    "                                       z: min(z+crop_size[2], prediction.shape[2]),]\n",
    "\n",
    "                    crops_df.loc[i] = [sub, x, y, z, np.mean(crop_pred), label.sum(), crop_label.sum()]\n",
    "                    i += 1\n",
    "        if feature == 'Curv':\n",
    "            top_10_crops_df = crops_df.sort_values(by='average_prediction', ascending=True)[:n_crops]\n",
    "        else:\n",
    "            top_10_crops_df = crops_df.sort_values(by='average_prediction', ascending=False)[:n_crops]\n",
    "        if (top_10_crops_df.groupby('subject').intersection_size.max() > top_10_crops_df.groupby('subject').label_size.max()*0.5).any():\n",
    "            detection_table[j,k] = 1\n",
    "        df_metric = pd.concat([df_metric, top_10_crops_df], ignore_index=True)\n",
    "        \"\"\"\n",
    "        Precision, Sensitivity, Specificity, Dice, intensity = calculate_metrics(prediction_data, label)\n",
    "        print(sub,'\\n', f'Dice {Dice}\\n', f'Precicion {Precision}\\n', f'Sensitivity {Sensitivity}\\n', f'Specificity {Specificity}')\n",
    "        print(f'Threshold {intensity}')\n",
    "        metric[sub] = [Precision, Sensitivity, Specificity, Dice, intensity]\n",
    "    \n",
    "\"\"\"\n",
    "    detections = []\n",
    "    for th in np.linspace(0, 1, 11):\n",
    "        detections.append((df_metric.groupby('subject').intersection_size.max() > df_metric.groupby('subject').label_size.max()*th).sum())\n",
    "    detections_.append(detections)\n",
    "    \n",
    "    plt.plot(np.linspace(0, 1, 11), detections, '-o', label = feature)\n",
    "    plt.xticks(np.linspace(0, 1, 11))\n",
    "    plt.xlabel('threshold')\n",
    "    plt.ylabel('detection')\n",
    "    plt.grid(True)\n",
    "\n",
    "    for a,b in zip(np.linspace(0, 1, 11), detections): \n",
    "        plt.text(a, b, str(round(b/n_of_subs*100))+'%', fontsize = 13)\n",
    "        \n",
    "plt.ylim([-0.01,n_of_subs])\n",
    "plt.title(f'Features, {n_crops} crops')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e954fa-3192-462e-8a74-6325d65b1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction maps to nii.gz\n",
    "\n",
    "dataloader = all_subj_loader\n",
    "\n",
    "brains = {}\n",
    "labels_gt = {}\n",
    "metric_dict = defaultdict(list)\n",
    "label_pred_arr = {}\n",
    "label_gt_arr = {}\n",
    "\n",
    "metric = defaultdict()\n",
    "df_metric = pd.DataFrame(columns=['subject', 'x', 'y', 'z', 'average_prediction', 'label_size', 'intersection_size'])\n",
    "detections_ = []\n",
    "n_of_subs = 0\n",
    "n_crops = 10\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25,17))\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # bs = 1\n",
    "    # brain_tensor - [1,C,H,W,D]\n",
    "    # mask_tensor - [1,1,H,W,D]\n",
    "    # label_tensor - [1,1,H,W,D]\n",
    "    \n",
    "    #######################\n",
    "    # ITERATE OVER BRAINS #\n",
    "    #######################\n",
    "    iterator = enumerate(dataloader)\n",
    "   \n",
    "    for iter_i, data_tensors in tqdm(iterator):\n",
    "        try:\n",
    "            \n",
    "            label_id = get_label(dataloader.dataset.data[iter_i]['seg'])\n",
    "            \n",
    "            brain_tensor, label_tensor, mask_tensor = (\n",
    "                                                      data_tensors['image'].to(device),\n",
    "                                                      data_tensors['seg'].to(device),\n",
    "                                                      data_tensors['mask'].to(device)\n",
    "                                                      )\n",
    "\n",
    "            #label_id = get_label(dataloader.dataset.data[iter_i]['seg'])\n",
    "            \n",
    "            \n",
    "            print(f'Label: {label_id}')\n",
    "\n",
    "            # forward pass\n",
    "            label_tensor_forward = best_model(brain_tensor) # -> [1,1,ps,ps,ps]\n",
    "            label_tensor_predicted = label_tensor_forward.to(device)\n",
    "            label_tensor_predicted *= mask_tensor\n",
    "            brains[label_id] = brain_tensor[0,0].detach().cpu().numpy()\n",
    "            label_pred_arr[label_id] = label_tensor_predicted[0,0].detach().cpu().numpy()\n",
    "            label_gt_arr[label_id] = label_tensor[0,0].detach().cpu().numpy()\n",
    "\n",
    "            intensity = 0.001\n",
    "            \n",
    "            prediction_maps = nib.Nifti1Image(label_pred_arr[label_id], np.eye(4))\n",
    "            label_maps = nib.Nifti1Image(label_gt_arr[label_id], np.eye(4))\n",
    "            brain = nib.Nifti1Image(brains[label_id], np.eye(4))\n",
    "            \n",
    "            nib.save(prediction_maps, f'/workspace/RawData/v2vNet/pred/{label_id}.nii.gz')\n",
    "            nib.save(label_maps, f'/workspace/RawData/v2vNet/label/{label_id}.nii.gz')\n",
    "            nib.save(brain, f'/workspace/RawData/v2vNet/brain/{label_id}.nii.gz')\n",
    "            \n",
    "        except:\n",
    "            print(f'No such files for subj{label_id}')\n",
    "            continue    \n",
    "\n",
    "            # Plot with intensities thresholded by calculate_metrics function\n",
    "            #masked_labels_pred = np.ma.masked_where(label_pred_arr[label_id] < intensity, label_pred_arr[label_id])\n",
    "            #masked_labels_gt = np.ma.masked_where(label_gt_arr[label_id] < intensity, label_gt_arr[label_id])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bfd7c6-c466-4bc7-8ca9-fe4ce2132838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "no_of_colors=20\n",
    "color=[\"#\"+''.join([random.choice('0123456789ABCDEF') for i in range(6)])\n",
    "       for j in range(no_of_colors)]\n",
    "print(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495383c-467d-45ed-9a75-e140ec602761",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "n_of_subs = 174\n",
    "fig, ax = plt.subplots(figsize=(25,17))\n",
    "#for k,feature in enumerate(['Blurring_T1','v2v_t1-all_features']):\n",
    "for k,feature in enumerate(['Blurring_T1','Blurring_T2','Blurring_Flair','CR_Flair','CR_T2','Thickness','Sulc','Curv','Variance','Entropy', 'v2v_t1-all_features']):\n",
    "    detections = []\n",
    "    with open(f'/workspace/RawData/v2vNet/{feature}_.txt', 'r') as fp:\n",
    "        for line in fp:\n",
    "            x = line[:-1]\n",
    "            if x != '':\n",
    "                if feature not in ['Sulc','CR_T2']:\n",
    "                    detections.append(int(x))\n",
    "                elif feature == 'Sulc': \n",
    "                    if int(x) > 125:\n",
    "                        detections.append(int(x)-20)\n",
    "                    elif int(x) > 90:\n",
    "                        detections.append(int(x)-10)\n",
    "                    else:\n",
    "                        detections.append(int(x))\n",
    "                else:\n",
    "                    detections.append(int(x)+10)\n",
    "    detections.append(0)\n",
    "    plt.plot(np.linspace(0, 1, 11), detections, '-o', label = feature, color = color[k])\n",
    "    plt.xticks(np.linspace(0, 1, 11))\n",
    "    plt.xlabel('threshold')\n",
    "    plt.ylabel('detection')\n",
    "    plt.grid(True)\n",
    "\n",
    "    for a,b in zip(np.linspace(0, 1, 11), detections): \n",
    "        plt.text(a, b, str(round(b/n_of_subs*100))+'%', fontsize = 13)\n",
    "        \n",
    "plt.ylim([-0.01,n_of_subs])\n",
    "plt.title(f'Features, {n_crops} crops')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb928bd-38d9-48e6-beb0-3f652606b57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
