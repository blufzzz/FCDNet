{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8f4907d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.measure import marching_cubes_lewiner, marching_cubes\n",
    "import nibabel\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import plotly.graph_objects as go\n",
    "import pymeshlab\n",
    "sorted = natsorted\n",
    "from numba import njit\n",
    "import cc3d\n",
    "import re\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "from tensorboardX import SummaryWriter  \n",
    "from IPython.core.debugger import set_trace\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from models.v2v import V2VModel\n",
    "\n",
    "import yaml\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "ffe22194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slices(brain_tensor, n_slices_show=5, mask_tensor=None):\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=3, nrows=n_slices_show, figsize=(15,n_slices_show*5))\n",
    "    X_max, Y_max, Z_max = brain_tensor.shape\n",
    "    for i in range(n_slices_show):\n",
    "\n",
    "        x_slice_pos = (X_max//(n_slices_show+2))*(i+1)\n",
    "        y_slice_pos = (Y_max//(n_slices_show+2))*(i+1)\n",
    "        z_slice_pos = (Z_max//(n_slices_show+2))*(i+1)\n",
    "\n",
    "        brain_tensor_x_slice = brain_tensor[x_slice_pos,:,:]\n",
    "        brain_tensor_y_slice = brain_tensor[:,y_slice_pos,:]\n",
    "        brain_tensor_z_slice = brain_tensor[:,:,z_slice_pos]\n",
    "\n",
    "        axes[i,0].imshow(brain_tensor_x_slice, 'gray')\n",
    "        axes[i,1].imshow(brain_tensor_y_slice, 'gray')\n",
    "        axes[i,2].imshow(brain_tensor_z_slice, 'gray')\n",
    "        \n",
    "        if mask_tensor is not None:\n",
    "            \n",
    "            mask_tensor_x_slice = mask_tensor[x_slice_pos,:,:]\n",
    "            mask_tensor_y_slice = mask_tensor[:,y_slice_pos,:]\n",
    "            mask_tensor_z_slice = mask_tensor[:,:,z_slice_pos]\n",
    "\n",
    "            axes[i,0].imshow(mask_tensor_x_slice, 'jet', interpolation='none', alpha=0.7)\n",
    "            axes[i,1].imshow(mask_tensor_y_slice, 'jet', interpolation='none', alpha=0.7)\n",
    "            axes[i,2].imshow(mask_tensor_z_slice, 'jet', interpolation='none', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def is_filled_volume(x,y,z,mask_tensor, threshold=0.5):\n",
    "    x1,x2 = x-patch_size//2, x+patch_size//2\n",
    "    y1,y2 = y-patch_size//2, y+patch_size//2\n",
    "    z1,z2 = z-patch_size//2, z+patch_size//2\n",
    "    volume = mask_tensor[x1:x2,y1:y2,z1:z2]\n",
    "    if volume.sum()/np.prod(volume.shape) > threshold:\n",
    "        return [x,y,z]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_symmetric_value(a, a_sym):\n",
    "    diff = a-a_sym\n",
    "    return a_sym - diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "2b9fee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchBrainMaskLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        paths = [os.path.join(root, p) for p in os.listdir(root)]\n",
    "        self.tensors_paths = list(filter())\n",
    "        self.indexes = list(filter())\n",
    "        \n",
    "        brain_label_\n",
    "        indexes_selected_\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        brain_tensor_torch, mask_tensor_torch = torch.load(self.paths[idx])\n",
    "        return brain_tensor_torch, mask_tensor_torch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "3030750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain_mask_paths = defaultdict(dict)\n",
    "# data_root = '../fcd_data/fmriprep/'\n",
    "# for sub_path in glob.glob(os.path.join(data_root,'sub-*/')):\n",
    "#     mask_path = glob.glob(os.path.join(sub_path,'anat/*Asym_desc-brain_mask*.nii.gz'))[0]\n",
    "#     T1_path = glob.glob(os.path.join(sub_path,'anat/*Asym_desc-preproc_T1w*.nii.gz'))[0]\n",
    "    \n",
    "#     label = os.path.basename(os.path.normpath(sub_path))\n",
    "#     brain_mask_paths[label]['mask_path'] = mask_path\n",
    "#     brain_mask_paths[label]['T1_path'] = T1_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "72e6bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_dict = defaultdict(dict)\n",
    "for p in os.listdir('../fcd_data/normalized_label'):\n",
    "    label = p.split('.')[0]\n",
    "    sub_root = f'../fcd_data/normalized_data/sub-{label}/anat/'\n",
    "    brain_path = glob.glob(os.path.join(sub_root, '*Asym_desc-preproc_T1w.nii.gz'))[0]\n",
    "    mask_path = glob.glob(os.path.join(sub_root, '*Asym_desc-brain_mask.nii.gz'))[0]\n",
    "    \n",
    "    label_path = f'../fcd_data/normalized_label/{p}'\n",
    "    \n",
    "    paths_dict[label]['label'] = label_path\n",
    "    paths_dict[label]['brain'] = brain_path    \n",
    "    paths_dict[label]['mask'] = mask_path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd/ibulygin/miniconda3/envs/fcd_hpc2/lib/python3.6/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning:\n",
      "\n",
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf141e7e2f204397a752b71b4ee32123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patch_size=64\n",
    "for label, path_dict in tqdm_notebook(paths_dict.items()):\n",
    "    \n",
    "    mask_tensor = nibabel.load(path_dict['mask']).get_fdata() > 0\n",
    "    brain_tensor = nibabel.load(path_dict['brain']).get_fdata()\n",
    "    brain_tensor = brain_tensor*mask_tensor.astype(int)\n",
    "    label_tensor = nibabel.load(path_dict['label']).get_fdata()\n",
    "    \n",
    "    brain_tensor_torch = torch.tensor(brain_tensor, dtype=torch.float)\n",
    "    label_tensor_torch = torch.tensor(label_tensor, dtype=torch.float)\n",
    "    \n",
    "    torch_tensor = torch.stack([brain_tensor_torch, label_tensor_torch])\n",
    "    torch.save(torch_tensor, f'../fcd_data/patches_dataset_{patch_size}/brain_label_{label}')\n",
    "\n",
    "    X,Y,Z = mask_tensor.shape\n",
    "\n",
    "    thresh_mask = (np.arange(X) < (X_mean - patch_size//2)) | (np.arange(X) > (X_mean + patch_size//2))\n",
    "    thresh_mask = np.tile(thresh_mask, (Y,Z,1)).transpose(2,0,1)\n",
    "    mask_tensor = mask_tensor*thresh_mask > 0\n",
    "\n",
    "    xyz_grid = np.stack(np.meshgrid(np.arange(X), np.arange(Y), np.arange(Z), indexing='ij'), -1)\n",
    "\n",
    "    indexes_selected = Parallel(n_jobs=-1)(delayed(is_filled_volume)(x,y,z,mask_tensor) \\\n",
    "                                           for x,y,z in xyz_grid[mask_tensor])\n",
    "\n",
    "    indexes_selected_ = np.array(list(filter(lambda x: x is not None, indexes_selected)))\n",
    "\n",
    "    np.save(f'../fcd_data/patches_dataset_{patch_size}/indexes_selected_{label}', indexes_selected_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ddd3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
