{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f4907d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nibabel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.core.debugger import set_trace\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from models.v2v import V2VModel\n",
    "\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from utils import show_slices, check_patch, pad_arrays, normalized, load, create_dicts\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "N_CPU = cpu_count()\n",
    "\n",
    "SEED = 42\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0336b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBrainMaskPatchLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, config, train=True):\n",
    "        \n",
    "        self.root = config.root\n",
    "        self.metadata_path = config.metadata_path\n",
    "        self.train = train\n",
    "        self.patch_size = config.patch_size\n",
    "        self.use_features = config.use_features\n",
    "        \n",
    "        self.concatenate_adjacent_patch = config.concatenate_adjacent_patch\n",
    "        self.difference_with_adjacent_patch = config.concatenate_adjacent_patch\n",
    "        \n",
    "        metadata_key = 'train' if train else 'test' \n",
    "        self.metadata = pd.read_csv(self.metadata_path).query(f\"is_train == {metadata_key}\")\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        metaindex = self.metadata.iloc[idx]\n",
    "        \n",
    "        label = 'tensor_' + metaindex.label\n",
    "        \n",
    "        tensor_dict = torch.load(os.path.join(self.root, label))\n",
    "        brain_tensor_torch = tensor_dict['brain']\n",
    "        mask_tensor_torch = tensor_dict['mask']\n",
    "        label_tensor_torch = tensor_dict['label']\n",
    "        \n",
    "        x,y,z = metaindex[['x','y','z']].astype(int)\n",
    "\n",
    "        x1,x2 = x-self.patch_size//2, x+self.patch_size//2\n",
    "        y1,y2 = y-self.patch_size//2, y+self.patch_size//2\n",
    "        z1,z2 = z-self.patch_size//2, z+self.patch_size//2\n",
    "\n",
    "        if self.use_features:\n",
    "            brain_patch = brain_tensor_torch[:,x1:x2,y1:y2,z1:z2] # [N_features,H,W,D] \n",
    "        else:\n",
    "            brain_patch = brain_tensor_torch[x1:x2,y1:y2,z1:z2].unsqueeze(0) # [1,H,W,D] \n",
    "            \n",
    "        label_patch = torch.tensor(metaindex.is_fcd, dtype=torch.long) # label\n",
    "    \n",
    "        return brain_patch, label_patch.unsqueeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d734846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load('../fcd_data/normalized_tensors/tensor_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106f640",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "916c0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_components = np.load('labels_info.npy', allow_pickle=True).item()\n",
    "single_component_keys = {k for k,v in labels_components.items() if len(v['cc3d'][0]) == 2}\n",
    "\n",
    "USE_GEOM_FEATURES = True\n",
    "GEOM_FEATURES = ['thickness', 'sulc', 'curv']\n",
    "\n",
    "root_label = '../fcd_data/normalized_label'\n",
    "root_data = '../fcd_data/normalized_data/'\n",
    "root_geom_features = '../fcd_data/preprocessed_data_anadezhda/'\n",
    "\n",
    "paths_dict = create_dicts(root_label,\n",
    "                         root_data,\n",
    "                         root_geom_features, \n",
    "                         single_component_keys,\n",
    "                         USE_GEOM_FEATURES, \n",
    "                         GEOM_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6257683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b5342d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = np.load('metadata.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c82ed",
   "metadata": {},
   "source": [
    "# Make metadata - all patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cee16262",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE=50\n",
    "pad=PATCH_SIZE//2\n",
    "DEVICE = torch.device('cuda:3')\n",
    "\n",
    "PERC_THRESHOLD = 0.9 # how much tissue\n",
    "LABEL_THRESHOLD = int((PATCH_SIZE**3)/100) # how much FCD pixels to be considered as FCD patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c1b54a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_seleted_root = f'../fcd_data/indexes_selected_P{PERC_THRESHOLD}_L{LABEL_THRESHOLD}'\n",
    "if not os.path.isdir(indexes_seleted_root):\n",
    "    os.makedirs(indexes_seleted_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd6849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 58/69 [1:35:44<18:44, 102.24s/it]"
     ]
    }
   ],
   "source": [
    "for split_type, split_keys in metadata.items():\n",
    "    for k in tqdm(split_keys):\n",
    "        \n",
    "        path_dict = paths_dict[k]\n",
    "        brain_tensor, mask_tensor, label_tensor = load(path_dict) # float, bool, int\n",
    "\n",
    "        X,Y,Z = mask_tensor.shape\n",
    "        X_mean = X//2\n",
    "\n",
    "        # get rid of a mid-brain\n",
    "        thresh_mask = (np.arange(X) < (X_mean - pad)) | (np.arange(X) > (X_mean + pad))\n",
    "        thresh_mask = np.tile(thresh_mask, (Y,Z,1)).transpose(2,0,1)\n",
    "        mask_tensor = mask_tensor*(thresh_mask > 0)\n",
    "\n",
    "\n",
    "        ###########################\n",
    "        # CREATE RELEVANT INDEXES #\n",
    "        ###########################\n",
    "        xyz_grid = np.stack(np.meshgrid(np.arange(pad, X-pad), \n",
    "                                        np.arange(pad, Y-pad), \n",
    "                                        np.arange(pad, Z-pad), \n",
    "                                        indexing='ij'), -1)\n",
    "\n",
    "        xyz_grid = xyz_grid[mask_tensor[pad:-pad,pad:-pad,pad:-pad]]\n",
    "\n",
    "        indexes_selected = Parallel(n_jobs=-1)(delayed(check_patch)(x,y,z,\\\n",
    "                                                                    mask_tensor,\\\n",
    "                                                                    label_tensor,\\\n",
    "                                                                    pad,\\\n",
    "                                                                    p_thresh=PERC_THRESHOLD) \\\n",
    "                                                               for x,y,z in xyz_grid)\n",
    "\n",
    "        indexes_selected = list(filter(lambda x: x is not None, indexes_selected))\n",
    "        if len(indexes_selected) > 0:\n",
    "            df = pd.DataFrame(indexes_selected)\n",
    "            df = df.query(f'p_mask >= {PERC_THRESHOLD} & (n_label >= {LABEL_THRESHOLD} | n_label==0)')\n",
    "\n",
    "            indexes_path = os.path.join(indexes_seleted_root, f'{k}')\n",
    "            df.to_csv(indexes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b58fe3",
   "metadata": {},
   "source": [
    "Making patches - bad idea!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac34652",
   "metadata": {},
   "source": [
    "# Make metadata - pivot patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUGMENTATION_STEPS = 2\n",
    "\n",
    "# metadata_pivot_patches = defaultdict(dict)\n",
    "\n",
    "# for split_type, split_keys in metadata.items():\n",
    "    \n",
    "#     for k in split_keys:\n",
    "        \n",
    "#         path_dict = paths_dict[k]\n",
    "        \n",
    "        \n",
    "#         brain_tensor, mask_tensor, label_tensor = load(path_dict) # float, bool, int\n",
    "#         label_info = labels_components[k]\n",
    "#         # center of the pivot patch with FCD\n",
    "#         center = label_info['center']\n",
    "        \n",
    "#         # shift around the pivot patch\n",
    "#         aug_iter = np.arange(-AUGMENTATION_STEPS, AUGMENTATION_STEPS+1)\n",
    "#         for shift in len(list(product(aug_iter, aug_iter, aug_iter))):\n",
    "#             info_patch = {}\n",
    "#             center_i = center + np.array(shift)\n",
    "#             info_patch['patch_center'] = center_i\n",
    "#             info_patch['subject'] = k\n",
    "#             info_patch['label'] = 1\n",
    "        \n",
    "#         X,Y,Z = mask_tensor.shape\n",
    "#         X_mean = X//2\n",
    "        \n",
    "#         # get rid of a mid-brain\n",
    "#         thresh_mask = (np.arange(X) < (X_mean - pad)) | (np.arange(X) > (X_mean + pad))\n",
    "#         thresh_mask = np.tile(thresh_mask, (Y,Z,1)).transpose(2,0,1)\n",
    "#         mask_tensor = mask_tensor*(thresh_mask > 0)\n",
    "        \n",
    "#         ###########################\n",
    "#         # CREATE RELEVANT INDEXES #\n",
    "#         ###########################\n",
    "#         xyz_grid = np.stack(np.meshgrid(np.arange(X), np.arange(Y), np.arange(Z), indexing='ij'), -1)\n",
    "#         xyz_grid = xyz_grid[mask_tensor]\n",
    "\n",
    "#         indexes_selected = Parallel(n_jobs=-1)(delayed(check_patch)(x,y,z,\\\n",
    "#                                                                     mask_tensor,\\\n",
    "#                                                                     label_tensor,\\\n",
    "#                                                                     pad) \\\n",
    "#                                                                for x,y,z in xyz_grid)\n",
    "\n",
    "#         indexes_selected = list(filter(lambda x: x is not None, indexes_selected))\n",
    "#         np.save('../fcd_data/indexes_selected/')\n",
    "#         break\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
