{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6d1b8-7e81-428a-b562-c494c7ee3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For nebula torch installation for A100\n",
    "# !pip3 install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "# !pip install -r ./requirements.txt\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e83d1-3a73-483e-898e-2d3e66bf0762",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import re, time, os, shutil, json\n",
    "from easydict import EasyDict as edict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from monai.data import list_data_collate\n",
    "import tempfile\n",
    "import monai\n",
    "from monai.data import DataLoader, Dataset \n",
    "from monai.transforms.intensity.array import ScaleIntensity\n",
    "from monai.transforms import (\n",
    "    LoadImage, EnsureChannelFirst, Spacing,\n",
    "    RandFlip, Resize, EnsureType,\n",
    "    LoadImaged, EnsureChannelFirstd,\n",
    "    Resized, EnsureTyped, Compose, ScaleIntensityd, \n",
    "    AddChanneld, MapTransform, AsChannelFirstd, EnsureType, \n",
    "    Activations, AsDiscrete, RandCropByPosNegLabeld, \n",
    "    RandRotate90d, LabelToMaskd, RandFlipd, RandRotated, Spacingd, RandAffined,\n",
    "    RandShiftIntensityd, Lambdad, MaskIntensityd\n",
    ")\n",
    "from utils import get_label\n",
    "\n",
    "from dataset import setup_dataloaders, setup_datafiles\n",
    "\n",
    "import configdot\n",
    "import torch\n",
    "from monai.config import print_config\n",
    "from IPython.core.debugger import set_trace\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_label(path):\n",
    "    '''\n",
    "    Extracts label from path, e.g.:\n",
    "    '/workspace/RawData/Features/preprocessed_data/label_bernaskoni/n16.nii.gz' -> 'n16'\n",
    "    '''\n",
    "    return path.split('/')[-1].split('.')[0]\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520904f-b42f-422e-8a6e-243cca291ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./MONAI_TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7eb035-ffe1-463f-abff-34241f6864b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MONAI_DATA_DIRECTORY'] = \"./MONAI_TMP\"\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb6a21-82f3-4648-8eac-9a3d94e539d3",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540078bf-f097-46f4-b4e5-826115eebb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configdot.parse_config('configs/config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c53e4-59df-4b79-89c8-23166ec7c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "DEVICE = config.opt.device if hasattr(config.opt, \"device\") else 0\n",
    "device = torch.device(DEVICE)\n",
    "torch.cuda.set_device(DEVICE)\n",
    "\n",
    "print('Setting GPU#:', DEVICE)\n",
    "print('Using GPU#:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b837f201-4a8d-41ea-a1fa-ba5bf584ab29",
   "metadata": {},
   "source": [
    "### Loading train-test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76bed8a-43d3-41ff-9d52-4d13bf47ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# subjects_list = np.load('./metadata/metadata_fcd_nG.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7008e09-e390-4491-a322-88527ec9e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8fed0-0afd-4d7f-98d2-393c8e6e004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = subjects_list.get('train')\n",
    "# val_list = subjects_list.get('test')\n",
    "\n",
    "# feat_params = config.dataset.features\n",
    "\n",
    "# print(len(train_list), len(val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27563e-d6ec-4b31-a8d3-dda524db1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c692f90-0580-40c9-881b-8f5e5b6672f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_loader, val_loader = setup_dataloaders(config)\n",
    "# train_files, val_files = setup_datafiles(subjects_list, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183016e-18fc-4104-87c7-a822c66241e3",
   "metadata": {},
   "source": [
    "### Transformation and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc144038-1fe9-4b55-8f10-2763c99c9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert config.default.interpolate\n",
    "# spatial_size_conf = tuple(config.default.interpolation_size)\n",
    "# #masked = config.dataset.trim_background\n",
    "# masked = True\n",
    "\n",
    "# def masked_transform(data_dict):\n",
    "#     data_dict[\"image\"] = data_dict[\"image\"] * data_dict[\"mask\"]\n",
    "#     return data_dict\n",
    "\n",
    "# if masked:\n",
    "#     keys=[\"image\", \"seg\", \"mask\"]\n",
    "#     sep_k=[\"seg\", \"mask\"]\n",
    "# else:\n",
    "#     keys=[\"image\", \"seg\"]\n",
    "#     sep_k=[\"seg\"]\n",
    "\n",
    "# if config.opt.augmentation:\n",
    "#     rot_range = 0.5 \n",
    "\n",
    "#     train_transf = Compose(\n",
    "#         [\n",
    "#             LoadImaged(keys=keys),\n",
    "#             EnsureChannelFirstd(keys=keys),\n",
    "#             RandRotated(keys=keys, \n",
    "#                         range_x=rot_range, \n",
    "#                         # range_y=rot_range, \n",
    "#                         # range_z=rot_range, \n",
    "#                         prob=1),\n",
    "#             RandFlipd(keys=keys, prob=0.5, spatial_axis=0),\n",
    "#             Spacingd(keys=sep_k, pixdim=1.0),\n",
    "#             Resized(keys=keys, spatial_size=spatial_size_conf),\n",
    "#             ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "#             # masked_transform,\n",
    "#             EnsureTyped(keys=keys, dtype=torch.float)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     val_transf = Compose(\n",
    "#         [\n",
    "#                 LoadImaged(keys=keys),\n",
    "#                 EnsureChannelFirstd(keys=keys),\n",
    "#                 Spacingd(keys=sep_k, pixdim=1.0),\n",
    "#                 Resized(keys=keys, spatial_size=spatial_size_conf),\n",
    "#                 ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "#                 # masked_transform,\n",
    "#                 EnsureTyped(keys=keys, dtype=torch.float),\n",
    "#             ]\n",
    "#     )\n",
    "    \n",
    "# else:\n",
    "#     raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e2af7-39d7-4658-9bc8-603fd5c2a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.opt.augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38cb2c8-b652-4947-ab74-1e21a2b96fda",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2a423-3a8e-4f38-a71d-717f3a2e9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_batch_size = 2\n",
    "# check_dataset = Dataset(data=train_files, transform=train_transf)\n",
    "# check_loader = DataLoader(check_dataset, \n",
    "#                           batch_size=check_batch_size, \n",
    "#                           num_workers=0, \n",
    "#                           collate_fn=list_data_collate, \n",
    "#                           pin_memory=torch.cuda.is_available(),\n",
    "#                           shuffle=True\n",
    "#                           )\n",
    "\n",
    "# check_data = monai.utils.misc.first(check_loader)\n",
    "# # check_data = monai.utils.misc.first(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48d17e-941e-4682-bf4c-f527af86b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for check_data_sample in check_dataset:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8887db5-c3ab-4a3b-bfca-e91f34ebf527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_data['image'][:,1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613270a-f4f9-4eb9-8512-5f0024342337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_data['image'][:,1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b750b09-057c-4c88-8208-4f3707f7b820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for k in range(check_batch_size):\n",
    "    \n",
    "#     image = check_data['image'][k]\n",
    "#     seg = check_data['seg'][k]\n",
    "#     mask = check_data['mask'][k]\n",
    "#     label = get_label(check_dataset.data[k]['seg'])\n",
    "    \n",
    "#     print(f\"image shape: {image.shape}\")\n",
    "    \n",
    "#     num_of_channels = len(feat_params)\n",
    "#     # choose z-coord where there is a label maximum over other axes\n",
    "#     label_pos = (seg > 0).sum(dim=(0,1,2)).argmax().item()\n",
    "    \n",
    "#     #mask = image[:1,...] <= 0 # `background mask\n",
    "    \n",
    "#     torch.sum(mask * image, dim=(-1,-2,-3)).type(torch.int) > 1\n",
    "\n",
    "#     fig = plt.figure(\"image\", (10, 5), dpi=200)\n",
    "#     ax1 = plt.subplot(1, 2, 1)\n",
    "#     #plt.title(f\"{feat_params[i]}\")\n",
    "#     ax1.imshow(image[1,:,:,label_pos], cmap='gray')\n",
    "#     ax2 = plt.subplot(1, 2, 2)\n",
    "#     ax2.imshow(mask[0,:,:,label_pos], alpha=0.5)\n",
    "    \n",
    "#     # plt.colorbar()\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "        \n",
    "#     fig.suptitle(label, fontsize=20, color='blue')\n",
    "#     # plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     if k > 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1746d-1ed6-4b48-9f2e-576ac864bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(feat_params)[torch.sum(mask * image, dim=(-1,-2,-3)).type(torch.int) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d342e-1ade-4b74-bb16-0107a37abbcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for k in range(check_batch_size):\n",
    "    \n",
    "#     image = check_data['image'][k]\n",
    "#     seg = check_data['seg'][k]\n",
    "#     label = get_label(check_dataset.data[k]['seg'])\n",
    "    \n",
    "#     print(f\"image shape: {image.shape}\")\n",
    "    \n",
    "#     num_of_channels = len(feat_params)\n",
    "#     # choose z-coord where there is a label maximum over other axes\n",
    "#     label_pos = (seg > 0).sum(dim=(0,1,2)).argmax().item()\n",
    "    \n",
    "#     mask = image[:1,...] <= 0 # `background mask\n",
    "#     torch.sum(mask * image, dim=(-1,-2,-3)).type(torch.int) > 1\n",
    "\n",
    "#     fig = plt.figure(\"image\", (5, 5), dpi=200)\n",
    "    \n",
    "#     plt.subplot(1, 1, 1)\n",
    "#     image_bin = image[-2,:,:,label_pos] > 0\n",
    "#     plt.imshow(image_bin, cmap='gray')\n",
    "#     plt.colorbar()\n",
    "#     #plt.title(f\"{feat_params[i]}, {image_bin.sum()}\")\n",
    "#     # plt.imshow(seg[0,:,:,label_pos], interpolation='none', cmap='Reds', alpha=0.3)\n",
    "#     # plt.imshow(seg[0,:,:,label_pos], interpolation='none', cmap='Reds', alpha=0.3)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "        \n",
    "#     fig.suptitle(label, fontsize=20, color='blue')\n",
    "#     # plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6702ed1-f77a-4fa3-b17b-b9df6ed3c449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# figures_per_row = 6 # for visualization\n",
    "# for k in range(check_batch_size):\n",
    "    \n",
    "#     image = check_data['image'][k]\n",
    "#     seg = check_data['seg'][k]\n",
    "#     label = get_label(check_dataset.data[k]['seg'])\n",
    "    \n",
    "#     print(f\"image shape: {image.shape}\")\n",
    "    \n",
    "#     num_of_channels = len(feat_params)\n",
    "#     # choose z-coord where there is a label maximum over other axes\n",
    "#     label_pos = (seg > 0).sum(dim=(0,1,2)).argmax().item()\n",
    "    \n",
    "#     mask = image[:1,...] <= 0 # `background mask\n",
    "#     torch.sum(mask * image, dim=(-1,-2,-3)).type(torch.int) > 1\n",
    "\n",
    "#     fig = plt.figure(\"image\", (len(feat_params), 5), dpi=200)\n",
    "#     for i in range(num_of_channels):\n",
    "#         nrows = int(np.ceil(num_of_channels/figures_per_row))\n",
    "#         cols = num_of_channels%figures_per_row\n",
    "#         plt.subplot(nrows, figures_per_row, i+1)\n",
    "#         plt.title(f\"{feat_params[i]}\")\n",
    "#         plt.imshow(image[i,:,:,label_pos] > 0, cmap=\"gray\")\n",
    "#         # plt.imshow(seg[0,:,:,label_pos], interpolation='none', cmap='Reds', alpha=0.3)\n",
    "#         # plt.imshow(seg[0,:,:,label_pos], interpolation='none', cmap='Reds', alpha=0.3)\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "        \n",
    "#     fig.suptitle(label, fontsize=20, color='blue')\n",
    "#     # plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27540a85-2e83-46c2-9e55-430ceebde584",
   "metadata": {},
   "source": [
    "# Check dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e33c9-6ebf-4bfe-8ea7-8e9dc0c05f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configdot.parse_config('configs/config.ini')\n",
    "# train_loader, val_loader = setup_dataloaders(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96206e91-0386-44f3-9a15-4c32545326f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_transform(data_dict):\n",
    "    data_dict[\"mask\"] = (data_dict[\"mask\"] > 0).astype(np.int)\n",
    "    data_dict[\"image\"] = data_dict[\"image\"] * (data_dict[\"mask\"])\n",
    "    return data_dict\n",
    "\n",
    "def setup_transformations(config):\n",
    "    \n",
    "    # assert False, 'Check mask mult!'\n",
    "    \n",
    "    assert config.default.interpolate\n",
    "    spatial_size_conf = tuple(config.default.interpolation_size)\n",
    "    \n",
    "    keys=[\"image\", \"seg\", \"mask\"]\n",
    "    sep_k=[\"seg\", \"mask\"]\n",
    "\n",
    "    if config.opt.augmentation:\n",
    "        rot_range = config.opt.rotation_range\n",
    "\n",
    "        train_transf = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=keys),\n",
    "                EnsureChannelFirstd(keys=keys),\n",
    "                RandRotated(keys=keys, \n",
    "                            range_x=0.5, #rot_range, \n",
    "                            # range_y=rot_range, \n",
    "                            # range_z=rot_range, \n",
    "                            prob=0.5),\n",
    "                RandFlipd(keys=keys, prob=0.5, spatial_axis=0),\n",
    "                Resized(keys=keys, spatial_size=spatial_size_conf),\n",
    "                Spacingd(keys=sep_k, pixdim=1.0),\n",
    "                ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "                mask_transform, \n",
    "                EnsureTyped(keys=sep_k, dtype=torch.float),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_transf = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=keys),\n",
    "                EnsureChannelFirstd(keys=keys),\n",
    "                Resized(keys=keys, spatial_size=spatial_size_conf),\n",
    "                Spacingd(keys=sep_k, pixdim=1.0),\n",
    "                ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "                mask_transform,\n",
    "                EnsureTyped(keys=sep_k, dtype=torch.float),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    return train_transf, val_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7851165-c9bd-40b4-b195-7802335c6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = config.dataset.metadata_path\n",
    "split_dict = np.load(metadata_path, allow_pickle=True).item()   \n",
    "\n",
    "train_files, val_files = setup_datafiles(split_dict, config)\n",
    "train_transf, val_transf = setup_transformations(config)\n",
    "\n",
    "# training dataset\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transf)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=config.opt.train_batch_size,\n",
    "    shuffle=config.dataset.shuffle_train,\n",
    "    num_workers=0,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# validation dataset\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transf)\n",
    "val_loader = DataLoader(val_ds, \n",
    "                        batch_size=config.opt.val_batch_size, \n",
    "                        num_workers=0, \n",
    "                        collate_fn=list_data_collate,\n",
    "                        shuffle=False # important not to shuffle, to ensure label correspondence\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e0fdf0-898d-4e87-be4a-f97c3cf0f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to check non-zero backgrounds in dataloader\n",
    "\n",
    "# features_cumsum = torch.zeros(len(config.dataset.features))\n",
    "# for train_batch in tqdm(train_loader):\n",
    "#     features_cumsum += train_batch['image'].sum(0)[:,:5,:5,:5].sum(dim=(-1,-2,-3))\n",
    "# for val_batch in tqdm(val_loader):\n",
    "#     features_cumsum += val_batch['image'].sum(0)[:,:5,:5,:5].sum(dim=(-1,-2,-3))\n",
    "# np.array(config.dataset.features)[features_cumsum > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30bd909-9519-47a0-95e6-14281dbbb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for check_data in tqdm(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d76d9-f26f-424e-be3a-649411b30d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = check_data['image'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4323ec-d2c1-4e8e-85a8-f7d89a91589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = check_data['mask']\n",
    "mask.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2d792-0b2c-4833-9db3-f13669c9e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2):\n",
    "    \n",
    "    image = check_data['image'][k]\n",
    "    seg = check_data['seg'][k]\n",
    "    mask = check_data['mask'][k]\n",
    "    label = get_label(train_ds.data[k]['seg'])\n",
    "    \n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    \n",
    "    # choose z-coord where there is a label maximum over other axes\n",
    "    label_pos = (seg > 0).sum(dim=(0,1,2)).argmax().item()\n",
    "    \n",
    "    fig = plt.figure(\"image\", (n_features*5, 5), dpi=200)\n",
    "    for i in range(n_features):\n",
    "        ax1 = plt.subplot(1, n_features, i+1)\n",
    "        ax1.imshow(image[i,:,:,label_pos], cmap='gray')\n",
    "        # ax2 = plt.subplot(1, 2*n_features, i+1)\n",
    "        ax1.imshow(mask[0,:,:,label_pos], alpha=0.2, cmap='jet')\n",
    "    \n",
    "    # plt.colorbar()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "        \n",
    "    fig.suptitle(label, fontsize=20, color='blue')\n",
    "    # plt.tight_layout()\n",
    "    plt.show()\n",
    "    if k > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06007b-b976-44e6-8bea-dc638c9a5e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
