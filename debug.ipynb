{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6d1b8-7e81-428a-b562-c494c7ee3f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # For nebula torch installation for A100\n",
    "#!pip3 install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "#!pip install -r ./requirements.txt\n",
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e83d1-3a73-483e-898e-2d3e66bf0762",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "import re, time, os, shutil, json\n",
    "from easydict import EasyDict as edict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from monai.data import list_data_collate\n",
    "import tempfile\n",
    "import monai\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.apps import CrossValidation\n",
    "from monai.transforms.intensity.array import ScaleIntensity\n",
    "from monai.transforms import (\n",
    "    LoadImage, EnsureChannelFirst, Spacing,\n",
    "    RandFlip, Resize, EnsureType,\n",
    "    LoadImaged, EnsureChannelFirstd,\n",
    "    Resized, EnsureTyped, Compose, ScaleIntensityd, \n",
    "    AddChanneld, MapTransform, AsChannelFirstd, EnsureType, \n",
    "    Activations, AsDiscrete, RandCropByPosNegLabeld, \n",
    "    RandRotate90d, LabelToMaskd, RandFlipd, RandRotated, Spacingd, RandAffined,\n",
    "    RandShiftIntensityd, Lambdad, MaskIntensityd\n",
    ")\n",
    "from utils import get_label, to_numpy\n",
    "\n",
    "from dataset import (\n",
    "    setup_dataloaders,\n",
    "    create_datafile,\n",
    "    setup_datafiles,\n",
    "    setup_transformations,\n",
    "    setup_dataloaders_cv\n",
    ")\n",
    "\n",
    "import configdot\n",
    "import torch\n",
    "from monai.config import print_config\n",
    "from IPython.core.debugger import set_trace\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_label(path):\n",
    "    '''\n",
    "    Extracts label from path, e.g.:\n",
    "    '/workspace/RawData/Features/preprocessed_data/label_bernaskoni/n16.nii.gz' -> 'n16'\n",
    "    '''\n",
    "    return path.split('/')[-1].split('.')[0]\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520904f-b42f-422e-8a6e-243cca291ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./MONAI_TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7eb035-ffe1-463f-abff-34241f6864b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MONAI_DATA_DIRECTORY'] = \"./MONAI_TMP\"\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb6a21-82f3-4648-8eac-9a3d94e539d3",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540078bf-f097-46f4-b4e5-826115eebb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configdot.parse_config('configs/config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c53e4-59df-4b79-89c8-23166ec7c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "DEVICE = config.opt.device if hasattr(config.opt, \"device\") else 0\n",
    "device = torch.device(DEVICE)\n",
    "torch.cuda.set_device(DEVICE)\n",
    "\n",
    "print('Setting GPU#:', DEVICE)\n",
    "print('Using GPU#:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b837f201-4a8d-41ea-a1fa-ba5bf584ab29",
   "metadata": {},
   "source": [
    "### Loading train-test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76bed8a-43d3-41ff-9d52-4d13bf47ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# subjects_list = np.load('./metadata/metadata_fcd_nG.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7008e09-e390-4491-a322-88527ec9e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8fed0-0afd-4d7f-98d2-393c8e6e004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = subjects_list.get('train')\n",
    "# val_list = subjects_list.get('test')\n",
    "\n",
    "# feat_params = config.dataset.features\n",
    "\n",
    "# print(len(train_list), len(val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27563e-d6ec-4b31-a8d3-dda524db1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c692f90-0580-40c9-881b-8f5e5b6672f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_loader, val_loader = setup_dataloaders(config)\n",
    "# train_files, val_files = setup_datafiles(subjects_list, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183016e-18fc-4104-87c7-a822c66241e3",
   "metadata": {},
   "source": [
    "### Transformation and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc144038-1fe9-4b55-8f10-2763c99c9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert config.default.interpolate\n",
    "# spatial_size_conf = tuple(config.default.interpolation_size)\n",
    "# #masked = config.dataset.trim_background\n",
    "# masked = True\n",
    "\n",
    "# def masked_transform(data_dict):\n",
    "#     data_dict[\"image\"] = data_dict[\"image\"] * data_dict[\"mask\"]\n",
    "#     return data_dict\n",
    "\n",
    "# if masked:\n",
    "#     keys=[\"image\", \"seg\", \"mask\"]\n",
    "#     sep_k=[\"seg\", \"mask\"]\n",
    "# else:\n",
    "#     keys=[\"image\", \"seg\"]\n",
    "#     sep_k=[\"seg\"]\n",
    "\n",
    "# if config.opt.augmentation:\n",
    "#     rot_range = 0.5 \n",
    "\n",
    "#     train_transf = Compose(\n",
    "#         [\n",
    "#             LoadImaged(keys=keys),\n",
    "#             EnsureChannelFirstd(keys=keys),\n",
    "#             RandRotated(keys=keys, \n",
    "#                         range_x=rot_range, \n",
    "#                         # range_y=rot_range, \n",
    "#                         # range_z=rot_range, \n",
    "#                         prob=1),\n",
    "#             RandFlipd(keys=keys, prob=0.5, spatial_axis=0),\n",
    "#             Spacingd(keys=sep_k, pixdim=1.0),\n",
    "#             Resized(keys=keys, spatial_size=spatial_size_conf),\n",
    "#             ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "#             # masked_transform,\n",
    "#             EnsureTyped(keys=keys, dtype=torch.float)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     val_transf = Compose(\n",
    "#         [\n",
    "#                 LoadImaged(keys=keys),\n",
    "#                 EnsureChannelFirstd(keys=keys),\n",
    "#                 Spacingd(keys=sep_k, pixdim=1.0),\n",
    "#                 Resized(keys=keys, spatial_size=spatial_size_conf),\n",
    "#                 ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "#                 # masked_transform,\n",
    "#                 EnsureTyped(keys=keys, dtype=torch.float),\n",
    "#             ]\n",
    "#     )\n",
    "    \n",
    "# else:\n",
    "#     raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e2af7-39d7-4658-9bc8-603fd5c2a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.opt.augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38cb2c8-b652-4947-ab74-1e21a2b96fda",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2a423-3a8e-4f38-a71d-717f3a2e9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_batch_size = 2\n",
    "# check_dataset = Dataset(data=train_files, transform=train_transf)\n",
    "# check_loader = DataLoader(check_dataset, \n",
    "#                           batch_size=check_batch_size, \n",
    "#                           num_workers=0, \n",
    "#                           collate_fn=list_data_collate, \n",
    "#                           pin_memory=torch.cuda.is_available(),\n",
    "#                           shuffle=True\n",
    "#                           )\n",
    "\n",
    "# check_data = monai.utils.misc.first(check_loader)\n",
    "# # check_data = monai.utils.misc.first(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48d17e-941e-4682-bf4c-f527af86b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for check_data_sample in check_dataset:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8887db5-c3ab-4a3b-bfca-e91f34ebf527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_data['image'][:,1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613270a-f4f9-4eb9-8512-5f0024342337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_data['image'][:,1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b750b09-057c-4c88-8208-4f3707f7b820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for k in range(check_batch_size):\n",
    "    \n",
    "#     image = check_data['image'][k]\n",
    "#     seg = check_data['seg'][k]\n",
    "#     mask = check_data['mask'][k]\n",
    "#     label = get_label(check_dataset.data[k]['seg'])\n",
    "    \n",
    "#     print(f\"image shape: {image.shape}\")\n",
    "    \n",
    "#     num_of_channels = len(feat_params)\n",
    "#     # choose z-coord where there is a label maximum over other axes\n",
    "#     label_pos = (seg > 0).sum(dim=(0,1,2)).argmax().item()\n",
    "    \n",
    "#     #mask = image[:1,...] <= 0 # `background mask\n",
    "    \n",
    "#     torch.sum(mask * image, dim=(-1,-2,-3)).type(torch.int) > 1\n",
    "\n",
    "#     fig = plt.figure(\"image\", (10, 5), dpi=200)\n",
    "#     ax1 = plt.subplot(1, 2, 1)\n",
    "#     #plt.title(f\"{feat_params[i]}\")\n",
    "#     ax1.imshow(image[1,:,:,label_pos], cmap='gray')\n",
    "#     ax2 = plt.subplot(1, 2, 2)\n",
    "#     ax2.imshow(mask[0,:,:,label_pos], alpha=0.5)\n",
    "    \n",
    "#     # plt.colorbar()\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "        \n",
    "#     fig.suptitle(label, fontsize=20, color='blue')\n",
    "#     # plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     if k > 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1746d-1ed6-4b48-9f2e-576ac864bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(feat_params)[torch.sum(mask * image, dim=(-1,-2,-3)).type(torch.int) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d342e-1ade-4b74-bb16-0107a37abbcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for k in range(check_batch_size):\n",
    "    \n",
    "#     image = check_data['image'][k]\n",
    "#     seg = check_data['seg'][k]\n",
    "#     label = get_label(check_dataset.data[k]['seg'])\n",
    "    \n",
    "#     print(f\"image shape: {image.shape}\")\n",
    "    \n",
    "#     num_of_channels = len(feat_params)\n",
    "#     # choose z-coord where there is a label maximum over other axes\n",
    "#     label_pos = (seg > 0).sum(dim=(0,1,2)).argmax().item()\n",
    "    \n",
    "#     mask = image[:1,...] <= 0 # `background mask\n",
    "#     torch.sum(mask * image, dim=(-1,-2,-3)).type(torch.int) > 1\n",
    "\n",
    "#     fig = plt.figure(\"image\", (5, 5), dpi=200)\n",
    "    \n",
    "#     plt.subplot(1, 1, 1)\n",
    "#     image_bin = image[-2,:,:,label_pos] > 0\n",
    "#     plt.imshow(image_bin, cmap='gray')\n",
    "#     plt.colorbar()\n",
    "#     #plt.title(f\"{feat_params[i]}, {image_bin.sum()}\")\n",
    "#     # plt.imshow(seg[0,:,:,label_pos], interpolation='none', cmap='Reds', alpha=0.3)\n",
    "#     # plt.imshow(seg[0,:,:,label_pos], interpolation='none', cmap='Reds', alpha=0.3)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "        \n",
    "#     fig.suptitle(label, fontsize=20, color='blue')\n",
    "#     # plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6702ed1-f77a-4fa3-b17b-b9df6ed3c449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# figures_per_row = 6 # for visualization\n",
    "# for k in range(check_batch_size):\n",
    "    \n",
    "#     image = check_data['image'][k]\n",
    "#     seg = check_data['seg'][k]\n",
    "#     label = get_label(check_dataset.data[k]['seg'])\n",
    "    \n",
    "#     print(f\"image shape: {image.shape}\")\n",
    "    \n",
    "#     num_of_channels = len(feat_params)\n",
    "#     # choose z-coord where there is a label maximum over other axes\n",
    "#     label_pos = (seg > 0).sum(dim=(0,1,2)).argmax().item()\n",
    "    \n",
    "#     mask = image[:1,...] <= 0 # `background mask\n",
    "#     torch.sum(mask * image, dim=(-1,-2,-3)).type(torch.int) > 1\n",
    "\n",
    "#     fig = plt.figure(\"image\", (len(feat_params), 5), dpi=200)\n",
    "#     for i in range(num_of_channels):\n",
    "#         nrows = int(np.ceil(num_of_channels/figures_per_row))\n",
    "#         cols = num_of_channels%figures_per_row\n",
    "#         plt.subplot(nrows, figures_per_row, i+1)\n",
    "#         plt.title(f\"{feat_params[i]}\")\n",
    "#         plt.imshow(image[i,:,:,label_pos] > 0, cmap=\"gray\")\n",
    "#         # plt.imshow(seg[0,:,:,label_pos], interpolation='none', cmap='Reds', alpha=0.3)\n",
    "#         # plt.imshow(seg[0,:,:,label_pos], interpolation='none', cmap='Reds', alpha=0.3)\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "        \n",
    "#     fig.suptitle(label, fontsize=20, color='blue')\n",
    "#     # plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27540a85-2e83-46c2-9e55-430ceebde584",
   "metadata": {},
   "source": [
    "# Check dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e33c9-6ebf-4bfe-8ea7-8e9dc0c05f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configdot.parse_config('configs/config.ini')\n",
    "# train_loader, val_loader = setup_dataloaders(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96206e91-0386-44f3-9a15-4c32545326f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_transform(data_dict):\n",
    "    data_dict[\"mask\"] = (data_dict[\"mask\"] > 0).astype(np.int)\n",
    "    data_dict[\"image\"] = data_dict[\"image\"] * (data_dict[\"mask\"])\n",
    "    return data_dict\n",
    "\n",
    "def setup_transformations(config):\n",
    "    \n",
    "    # assert False, 'Check mask mult!'\n",
    "    \n",
    "    assert config.default.interpolate\n",
    "    spatial_size_conf = tuple(config.default.interpolation_size)\n",
    "    \n",
    "    keys=[\"image\", \"seg\", \"mask\"]\n",
    "    sep_k=[\"seg\", \"mask\"]\n",
    "\n",
    "    if config.opt.augmentation:\n",
    "        rot_range = config.opt.rotation_range\n",
    "\n",
    "        train_transf = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=keys),\n",
    "                EnsureChannelFirstd(keys=keys),\n",
    "                RandRotated(keys=keys, \n",
    "                            range_x=rot_range, #rot_range, \n",
    "                            range_y=rot_range, \n",
    "                            range_z=rot_range, \n",
    "                            prob=0.5),\n",
    "                RandFlipd(keys=keys, prob=0.5, spatial_axis=0),\n",
    "                Resized(keys=keys, spatial_size=spatial_size_conf),\n",
    "                Spacingd(keys=sep_k, pixdim=1.0),\n",
    "                ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "                mask_transform, \n",
    "                EnsureTyped(keys=sep_k, dtype=torch.float),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_transf = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=keys),\n",
    "                EnsureChannelFirstd(keys=keys),\n",
    "                Resized(keys=keys, spatial_size=spatial_size_conf),\n",
    "                Spacingd(keys=sep_k, pixdim=1.0),\n",
    "                ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "                mask_transform,\n",
    "                EnsureTyped(keys=sep_k, dtype=torch.float),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    return train_transf, val_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7851165-c9bd-40b4-b195-7802335c6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = config.dataset.metadata_path\n",
    "split_dict = np.load(metadata_path, allow_pickle=True).item()   \n",
    "\n",
    "train_files, val_files = setup_datafiles(split_dict, config)\n",
    "train_transf, val_transf = setup_transformations(config)\n",
    "\n",
    "# training dataset\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transf)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=config.opt.train_batch_size,\n",
    "    shuffle=config.dataset.shuffle_train,\n",
    "    num_workers=0,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# validation dataset\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transf)\n",
    "val_loader = DataLoader(val_ds, \n",
    "                        batch_size=config.opt.val_batch_size, \n",
    "                        num_workers=0, \n",
    "                        collate_fn=list_data_collate,\n",
    "                        shuffle=False # important not to shuffle, to ensure label correspondence\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c33e0a-551a-43e9-b3f5-d9fdab2aaa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader_aug = DataLoader(monai.data.Dataset(data=val_files, transform=train_transf), \n",
    "                        batch_size=config.opt.val_batch_size, \n",
    "                        num_workers=0, \n",
    "                        collate_fn=list_data_collate,\n",
    "                        shuffle=False # important not to shuffle, to ensure label correspondence\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0083a4d3-8e3f-4db8-aab7-efd0408dc966",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(val_loader_aug))\n",
    "mask = data['mask'][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f622958-1c19-4f20-8f4e-9143fbceeecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins=50\n",
    "h1 = torch.histc(data['image'][0,0][mask > 0], min=0, max=1, bins=nbins).numpy()\n",
    "h2 = torch.histc(data['image'][0,1][mask > 0], min=0, max=1, bins=nbins).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa317f-88df-407f-8019-f6e009711751",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1e-10,1,nbins), h1, alpha=0.5) # , align='edge'\n",
    "plt.plot(np.linspace(1e-10,1,nbins), h2, alpha=0.2)\n",
    "# plt.xticks(np.arange(100)[::20], np.linspace(0,1,100)[::20])\n",
    "# plt.xticks(np.linspace(0,1,100)[::20], np.linspace(0,1,100)[::20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40ea63-a7e1-42f0-8b16-7112ff0ac9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = data['image'][0,0]\n",
    "# curv = data['image'][0,1]\n",
    "\n",
    "# plt.hist(image[mask > 0] ,bins=50, alpha=0.5)\n",
    "# plt.hist(curv[mask > 0] ,bins=50, alpha=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6513d-344c-431b-95e8-6acc933a0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction_slice(b_ind=0, c_ind=0):\n",
    "    \n",
    "    '''\n",
    "    b_ind - batch_index\n",
    "    c_ind - channel index for `brain_tensor`\n",
    "    brain_tensor - [bs,C,1,H,W,D]\n",
    "    mask_tensor - [bs,1,1,H,W,D]\n",
    "    label_tensor - [bs,1,1,H,W,D]\n",
    "    label_tensor_predicted - [bs,1,1,H,W,D]\n",
    "    '''\n",
    "    \n",
    "    label_pos = (label_tensor[b_ind,0] > 0).sum(dim=(0,1)).argmax().item()\n",
    "    \n",
    "    fig = plt.figure(\"image\", (3*5, 5), dpi=100)\n",
    "    \n",
    "    ax1 = plt.subplot(1, 3, 1)\n",
    "    ax1.imshow(to_numpy(brain_tensor[b_ind,c_ind,:,:,label_pos]), cmap='gray')\n",
    "    # ax1.imshow(to_numpy(mask_tensor[b_ind,0,:,:,label_pos]), alpha=0.2, cmap='Reds')\n",
    "    ax1.imshow(to_numpy(label_tensor[b_ind,0,:,:,label_pos]), alpha=0.6, cmap='Reds')\n",
    "    \n",
    "    ax2 = plt.subplot(1, 3, 2)\n",
    "    ax2.imshow(to_numpy(brain_tensor[b_ind,c_ind,:,:,label_pos]), cmap='gray')\n",
    "    # ax2.imshow(to_numpy(mask_tensor[b_ind,0,:,:,label_pos]), alpha=0.2, cmap='Reds')\n",
    "    ax2.imshow(to_numpy(label_tensor_predicted[b_ind,0,:,:,label_pos]), alpha=0.6, cmap='Reds')\n",
    "    \n",
    "    ax3 = plt.subplot(1, 3, 3)\n",
    "    ax3.imshow(to_numpy(mask_tensor[b_ind,0,:,:,label_pos]), cmap='jet')\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecec196-4a94-42c1-a1c2-db9c9915574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_seg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10777574-45c1-4026-beb1-50adcdb38a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_tensors in val_loader_aug:\n",
    "    brain_tensor, label_tensor, mask_tensor = (\n",
    "                                                data_tensors['image'].to(device),\n",
    "                                                data_tensors['seg'].to(device),\n",
    "                                                data_tensors['mask'].to(device)\n",
    "                                                )\n",
    "label_tensor_predicted = label_tensor\n",
    "\n",
    "show_prediction_slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c052e-6d3a-4574-9ced-dc762cd9bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,(data, data_aug) in enumerate(zip(val_loader, val_loader_aug)):\n",
    "\n",
    "    image = data['image'][0,1] \n",
    "    image_aug = data_aug['image'][0,0]\n",
    "    \n",
    "    seg = data['seg'][0,0]\n",
    "    seg_aug = data_aug['seg'][0,0]\n",
    "    \n",
    "    mask = data['mask'][0,0]\n",
    "    mask_aug = data_aug['mask'][0,0]\n",
    "    \n",
    "    label = get_label(val_loader.dataset.data[k]['seg'])\n",
    "    \n",
    "    # choose z-coord where there is a label maximum over other axes\n",
    "    label_pos = (seg > 0).sum(dim=(0,1)).argmax().item()\n",
    "    \n",
    "    fig = plt.figure(\"image\", (2*5, 5), dpi=200)\n",
    "\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    ax1.imshow(image[:,:,label_pos]) # , cmap='gray'\n",
    "    ax1.imshow(mask[:,:,label_pos], alpha=0.2, cmap='jet')\n",
    "    \n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    ax2.imshow(image_aug[:,:,label_pos]) # , cmap='gray'\n",
    "    ax2.imshow(mask_aug[:,:,label_pos], alpha=0.2, cmap='jet')\n",
    "    \n",
    "    # plt.colorbar()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "        \n",
    "    fig.suptitle(label, fontsize=20, color='blue')\n",
    "    # plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if k > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c665f8a-6604-48b9-af9c-c1e1a858b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['image'][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e0fdf0-898d-4e87-be4a-f97c3cf0f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to check non-zero backgrounds in dataloader\n",
    "\n",
    "# features_cumsum = torch.zeros(len(config.dataset.features))\n",
    "# for train_batch in tqdm(train_loader):\n",
    "#     features_cumsum += train_batch['image'].sum(0)[:,:5,:5,:5].sum(dim=(-1,-2,-3))\n",
    "# for val_batch in tqdm(val_loader):\n",
    "#     features_cumsum += val_batch['image'].sum(0)[:,:5,:5,:5].sum(dim=(-1,-2,-3))\n",
    "# np.array(config.dataset.features)[features_cumsum > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d76d9-f26f-424e-be3a-649411b30d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = check_data['image'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4323ec-d2c1-4e8e-85a8-f7d89a91589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = check_data['mask']\n",
    "mask.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2d792-0b2c-4833-9db3-f13669c9e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2):\n",
    "    \n",
    "    image = check_data['image'][k]\n",
    "    seg = check_data['seg'][k]\n",
    "    mask = check_data['mask'][k]\n",
    "    label = get_label(train_ds.data[k]['seg'])\n",
    "    \n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    \n",
    "    # choose z-coord where there is a label maximum over other axes\n",
    "    label_pos = (seg > 0).sum(dim=(0,1,2)).argmax().item()\n",
    "    \n",
    "    fig = plt.figure(\"image\", (n_features*5, 5), dpi=200)\n",
    "    for i in range(n_features):\n",
    "        ax1 = plt.subplot(1, n_features, i+1)\n",
    "        ax1.imshow(image[i,:,:,label_pos], cmap='gray')\n",
    "        # ax2 = plt.subplot(1, 2*n_features, i+1)\n",
    "        ax1.imshow(mask[0,:,:,label_pos], alpha=0.2, cmap='jet')\n",
    "    \n",
    "    # plt.colorbar()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "        \n",
    "    fig.suptitle(label, fontsize=20, color='blue')\n",
    "    # plt.tight_layout()\n",
    "    plt.show()\n",
    "    if k > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885fe961-03fd-48ba-924c-ab4e4f0583c9",
   "metadata": {},
   "source": [
    "### Cross - Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51dbf1e-79bd-4cce-99ee-4d7e9e79dc09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loaders, val_loaders, test_loader = setup_dataloaders_cv(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb61de0-0e7f-4894-9f8f-0f181cb401a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@abstractmethod\n",
    "class CVDataset(ABC, CacheDataset):\n",
    "    \"\"\"\n",
    "    Base class to generate cross validation datasets.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        transform,\n",
    "        cache_num=sys.maxsize,\n",
    "        cache_rate=1.0,\n",
    "        num_workers=None,\n",
    "    ) -> None:\n",
    "        data = self._split_datalist(datalist=data)\n",
    "        CacheDataset.__init__(\n",
    "            self, data, transform, cache_num=cache_num, cache_rate=cache_rate, num_workers=num_workers\n",
    "        )\n",
    "\n",
    "    def _split_datalist(self, datalist):\n",
    "        raise NotImplementedError(f\"Subclass {self.__class__.__name__} must implement this method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75deee0f-1a25-4f55-9f5b-2d22ade7719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_transform(data_dict):\n",
    "    data_dict[\"mask\"] = (data_dict[\"mask\"] > 0).astype(np.int)\n",
    "    data_dict[\"image\"] = data_dict[\"image\"] * (data_dict[\"mask\"])\n",
    "    return data_dict\n",
    "    \n",
    "spatial_size_conf = ([128, 128, 128])\n",
    "    \n",
    "keys=[\"image\", \"seg\", \"mask\"]\n",
    "sep_k=[\"seg\", \"mask\"]\n",
    "\n",
    "rot_range = 0.15\n",
    "\n",
    "\n",
    "train_transf = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=keys),\n",
    "                EnsureChannelFirstd(keys=keys),\n",
    "                RandRotated(keys=keys, \n",
    "                            range_x=rot_range, #rot_range, \n",
    "                            range_y=rot_range, \n",
    "                            range_z=rot_range, \n",
    "                            prob=0.5),\n",
    "                RandFlipd(keys=keys, prob=0.5, spatial_axis=0),\n",
    "                Resized(keys=keys, spatial_size=spatial_size_conf),\n",
    "                Spacingd(keys=sep_k, pixdim=1.0),\n",
    "                ScalePerfectly(keys=['image'], \n",
    "                               minv=[None, None, -4, 10, ...], \n",
    "                               maxv=[None, None, -4, 10, ...], \n",
    "                               channelwise=True)\n",
    "                # ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "                mask_transform, \n",
    "                EnsureTyped(keys=sep_k, dtype=torch.float),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "val_transf = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=keys),\n",
    "                EnsureChannelFirstd(keys=keys),\n",
    "                Resized(keys=keys, spatial_size=spatial_size_conf),\n",
    "                Spacingd(keys=sep_k, pixdim=1.0),\n",
    "                ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "                mask_transform,\n",
    "                EnsureTyped(keys=sep_k, dtype=torch.float),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac589dac-23d5-4a9b-acb0-a364b8ff5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 8\n",
    "folds = list(range(num))\n",
    "\n",
    "cvdataset = CrossValidation(\n",
    "    dataset_cls=CVDataset,\n",
    "    data=dataset_filepaths[0][:80],\n",
    "    nfolds=8,\n",
    "    seed=42,\n",
    "    transform=train_transf,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f183e75-4137-4df9-a769-fe1157535137",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d5773-6190-4562-a327-ea7213fa26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dss = [cvdataset.get_dataset(folds=folds[0: i] + folds[(i + 1):]) for i in folds]\n",
    "val_dss = [cvdataset.get_dataset(folds=i, transform=val_transf) for i in range(num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425a1c8-686f-40b7-951a-e48b4793b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = [DataLoader(train_dss[i], batch_size=2, shuffle=True, num_workers=0) for i in folds]\n",
    "val_loaders = [DataLoader(val_dss[i], batch_size=1, num_workers=0) for i in folds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b12f37-6921-44a0-a18d-3c1e8f3cc429",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CacheDataset(data=dataset_filepaths[0][80:], transform=val_transf, num_workers=None)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562dd9d-16eb-4f74-abef-9e8e99f2b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e78c7-37f7-4226-b242-76aff27d1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dss[0]:\n",
    "    #print(len(i))\n",
    "    file_path = i['image_meta_dict']['filename_or_obj']\n",
    "    index = file_path.split('/')[5].split('-')[-1]\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bdb34-9d76-4afd-9305-f472c68875ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.v2v import V2VModel\n",
    "\n",
    "assert config.model.name == \"v2v\"\n",
    "best_model = V2VModel(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7c747-1e62-418a-9b2a-4482498d2ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
