[default]
# `mask_transform` is placed at the end of Compose and mask is re-casted to 0 and 1 float values
# added `minmax_scaling_specified_wrapper` to ensure different scaling from `scaling_metadata_path`
# regular batch-size equal 2

# experiment_comment = 'v2v-large-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASKint-t1-all_scaler-trial1'
experiment_comment = 'v2v-IN_autocast_DICE-d-0.9-g1-w-0.1_GC-1_lr-1e-3_nG-bs1-AUG-MASKint-t1-t2-flair_torchio'

log_dir = '/workspace/RawData/FCDNet/logs/debug/augmentation_2'
make_logs = True
interpolate = True # set by default
interpolation_size = [128, 128, 128]
random_seed = 42

[opt] 
device = 1
criterion = "Dice" # use with positive gamma
delta = 0.9 #
gamma = 1 #
weight = 0.1 # weight corrsepond to region-based (e.g. tversky)
use_scaler = True
grad_clip = 1

start_epoch = 0
n_epochs = 500

augmentation = True
# augmentation params
rand_affine_prob = 0.5
rotation_range = 0.15 # in radians
shear_range = 0.08 
scale_range = 0.
translate_range = 0.1
noise_std = 1e-2
flip_prob = 0.5
rand_zoom_prob = 0.25

train_batch_size = 1
val_batch_size = 1

lr = 0.001  
save_model = True

[model]
name = "v2v"
output_channels = 1 # FCD and background
allow_matching_interpolation = True
max_channel_encoder_decoder = 128 
sigmoid = True
activation = 'LeakyReLU'
normalization = 'instance_norm' # 'group_norm' #'instance_norm'
use_greedy_saving = True
target_metric_name = 'dice_score'
# weights = '/workspace/RawData/FCDNet/logs/features_comparison/t1_curv/v2v-IN_autocast_DICE_lr-1e-3_nG-bs2-AUG-MASKint-t1-curv_scaler-trial1@18.08.2022-19/checkpoints/weights_293.pth'

[dataset]
save_best_val_predictions = False
trim_background = True # add Mask

#features = ['image', 't2', 'flair', 'blurring-t1', 'blurring-t2', 'blurring-Flair', 'cr-t2', 'cr-Flair', 'thickness', 'curv', 'sulc', 'variance', 'entropy']

features = ['image', 't2', 'flair', 'blurring-t1', 'blurring-t2', 'blurring-Flair', 'cr-t2', 'cr-Flair', 'thickness', 'curv', 'sulc', 'variance', 'entropy']
#features = ['image', 't2', 'flair']

root = '/nfs/tom/ibulygin/fcd_data/tensors_yarkin_data' # chng tp /mnt/... or /nfs/... for ws-*
metadata_path = 'metadata/metadata_fcd_nG.npy'
scaling_method = 'torchio'  # 'scale_metadata' 
# uncomment to use specific statistics for normalization is scaling_method = 'scale_metadata'
#scaling_metadata_path = 'metadata/minmax_scaling_metadata.npy'

dataset_type = 'fcd'
shuffle_train = True
