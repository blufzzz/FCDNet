{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c58c8-3a33-4783-8fd5-638e0df0a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62a974-ef88-47ab-ab48-85e463436d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
    "!pip install -q \"monai-weekly[nibabel, tqdm, einops]\"\n",
    "!python3 -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e83d1-3a73-483e-898e-2d3e66bf0762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time, os, shutil, json\n",
    "from easydict import EasyDict as edict\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk  # noqa: N813\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from monai.data import create_test_image_3d, list_data_collate, decollate_batch, pad_list_data_collate\n",
    "import tempfile\n",
    "import monai\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import ITKReader, PILReader, ImageDataset, DataLoader, Dataset, PersistentDataset, CacheDataset, ArrayDataset\n",
    "from monai.networks.layers import Norm\n",
    "from monai.transforms import (\n",
    "    LoadImage, EnsureChannelFirst, Spacing,\n",
    "    RandFlip, Resize, EnsureType,\n",
    "    LoadImaged, EnsureChannelFirstd,\n",
    "    Resized, EnsureTyped, Compose, ScaleIntensityd, AddChanneld, MapTransform, AsChannelFirstd, EnsureType, Activations, AsDiscrete,\n",
    "    RandCropByPosNegLabeld, RandRotate90d, LabelToMaskd, RandFlipd, RandRotated, Spacingd, RandAffined\n",
    ")\n",
    "#from monai.networks.nets import UNETR\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.transforms.intensity.array import ScaleIntensity\n",
    "from monai.metrics import DiceMetric\n",
    "import configdot\n",
    "import torch\n",
    "from monai.config import print_config\n",
    "#from monai.engines import create_multigpu_supervised_trainer\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520904f-b42f-422e-8a6e-243cca291ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./MONAI_TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540078bf-f097-46f4-b4e5-826115eebb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configdot.parse_config('configs/config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4e7b4-ec4a-4bba-8100-bf178cffd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MONAI_DATA_DIRECTORY'] = \"./MONAI_TMP\"\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec310a-e595-4c13-8da4-18b96c0a59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/workspace/RawData/Features'\n",
    "OUTPUT_DIR = '/workspace/RawData/Features/BIDS'\n",
    "TMP_DIR = '/workspace/Features/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fdcf1e-9692-4134-8ff0-802b0d76c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /workspace/RawData/Features/prep_wf | wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922444c2-a26a-45a0-a0a1-3e61d4c5f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_feature_maps(sub, feature):\n",
    "    global BASE_DIR\n",
    "    global OUTPUT_DIR\n",
    "    global TMP_DIR\n",
    "    if feature == 'image':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'sub-{sub}_t1_brain-final.nii.gz')\n",
    "    elif feature == 't2':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'sub-{sub}_t2_brain-final.nii.gz')\n",
    "    elif feature == 'flair':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'sub-{sub}_fl_brain-final.nii.gz')\n",
    "    elif feature == 'blurring-t1':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'Blurring_T1.nii.gz')\n",
    "    elif feature == 'blurring-Flair':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'Blurring_Flair.nii.gz')\n",
    "    elif feature == 'cr-t2':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'CR_T2.nii')\n",
    "    elif feature == 'cr-Flair':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'CR_Flair.nii')\n",
    "    elif feature == 'thickness':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'thickness_mni.nii')\n",
    "    elif feature == 'curv':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'curv_mni.nii')\n",
    "    elif feature == 'sulc':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'sulc_mni.nii')\n",
    "    elif feature == 'variance':\n",
    "        feature_map = os.path.join(BASE_DIR, f'preprocessed_data', 'var', f'sub-{sub}_var.nii.gz')\n",
    "    elif feature == 'mask':\n",
    "        feature_map = os.path.join(BASE_DIR, f'prep_wf', f'sub-{sub}', f'sub-{sub}_t1_brain-final_mask.nii.gz')\n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76bed8a-43d3-41ff-9d52-4d13bf47ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "subjects_list = np.load('./metadata/metadata_fcd_nG.npy', allow_pickle=True)\n",
    "subjects_list.item().get('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8fed0-0afd-4d7f-98d2-393c8e6e004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = subjects_list.item().get('train')\n",
    "val_list = subjects_list.item().get('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066049c8-93ab-4499-87dc-079594da3b4d",
   "metadata": {},
   "source": [
    "### images_list also Checks that features and labels available and returns number of available subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603dab81-6b1d-4cf0-bc54-77a596a32d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images_list = []\n",
    "subject_list = []\n",
    "feat_params = config.dataset.features\n",
    "# {'image': ['/workspace/Features/preprocessed_data/new_pipeline/sub-8/sub-8_acq-T1Mprage_space-MNI152NLint2_seq-T1w_brain.nii.gz',\n",
    "#   '/workspace/Features/preprocessed_data/thickness/norm-8.nii.gz',\n",
    "#   '/workspace/Features/preprocessed_data/curv/norm-8.nii.gz',\n",
    "#           ]\n",
    "# }\n",
    "\n",
    "for i in os.listdir(OUTPUT_DIR):\n",
    "    sub_ind = re.findall('-(.[a-zA-Z0-9]*|[0-9])', str(i))\n",
    "    #if sub_ind and not any(x in sub_ind[0] for x in matches): # subjects with 'n', 'G', 'NS', 'C' won't be included\n",
    "    if sub_ind:\n",
    "        subject_list.append(sub_ind[0])\n",
    "        \n",
    "#random_seed = 666    \n",
    "#train_list, val_list = train_test_split(subject_list, shuffle=False, train_size=0.80, random_state=random_seed)\n",
    "\n",
    "train_subs_indcs = []\n",
    "train_files = []\n",
    "\n",
    "for sub in train_list:\n",
    "    images_per_sub = dict()\n",
    "    images_per_sub['image'] = []\n",
    "    for feat in feat_params:\n",
    "        map_path = assign_feature_maps(sub, feat)\n",
    "        if os.path.isfile(map_path):\n",
    "            images_per_sub['image'].append(map_path)\n",
    "        else:\n",
    "            print(f'No feature {feat} for sub {sub} in train data')\n",
    "            continue\n",
    "    if len(images_per_sub['image']) == len(feat_params):\n",
    "        seg_path = os.path.join(BASE_DIR, 'preprocessed_data/label_bernaskoni', f'{sub}.nii.gz')\n",
    "        if os.path.isfile(seg_path):\n",
    "            images_per_sub['seg'] = seg_path\n",
    "        else:\n",
    "            continue\n",
    "        train_subs_indcs.append(sub)\n",
    "        train_files.append(images_per_sub)\n",
    "\n",
    "val_subs_indcs = []\n",
    "val_files = []\n",
    "\n",
    "for sub in val_list:\n",
    "    images_per_sub = dict()\n",
    "    images_per_sub['image'] = []\n",
    "    for feat in feat_params:\n",
    "        map_path = assign_feature_maps(sub, feat)\n",
    "        if os.path.isfile(map_path):\n",
    "            images_per_sub['image'].append(map_path)\n",
    "        else:\n",
    "            print(f'No feature {feat} for sub {sub} in val data')\n",
    "            continue\n",
    "    if len(images_per_sub['image']) == len(feat_params):\n",
    "        seg_path = os.path.join(BASE_DIR, 'preprocessed_data/label_bernaskoni', f'{sub}.nii.gz')\n",
    "        if os.path.isfile(seg_path):\n",
    "            images_per_sub['seg'] = seg_path\n",
    "        else:\n",
    "            print(f'No {seg_path} for sub {sub}')\n",
    "            continue\n",
    "        val_subs_indcs.append(sub)\n",
    "        val_files.append(images_per_sub)\n",
    "\n",
    "print(f\"Train set length: {len(train_files)}\\nTest set length: {len(val_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183016e-18fc-4104-87c7-a822c66241e3",
   "metadata": {},
   "source": [
    "## Transformation and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc144038-1fe9-4b55-8f10-2763c99c9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_size_conf = tuple(config.default.interpolation_size)\n",
    "\n",
    "train_transf = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"seg\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"seg\"]),\n",
    "        RandRotated(keys=[\"image\", \"seg\"], range_x=0.25, range_y=0.25, range_z=0.25, prob=0.9),\n",
    "        RandFlipd(keys=[\"image\", \"seg\"], prob=0.5, spatial_axis=0),\n",
    "        Resized(keys=[\"image\", \"seg\"], spatial_size=spatial_size_conf, mode=('area', 'nearest')),\n",
    "        Spacingd(keys=['seg'], pixdim=1.0),\n",
    "        ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "        #RandFlipd(keys=[\"image\", \"seg\"], prob=0.5, spatial_axis=1),\n",
    "        #RandFlipd(keys=[\"image\", \"seg\"], prob=0.5, spatial_axis=2),\n",
    "        #RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[224, 224, 144], random_size=False),\n",
    "        #RandRotated(keys=[\"image\", \"seg\"], range_x=0.0, range_y=0.0, range_z=0.75, prob=1),\n",
    "        EnsureTyped(keys=[\"image\", \"seg\"], dtype=torch.float),\n",
    "    ]\n",
    ")\n",
    "val_transf = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"seg\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"seg\"]),\n",
    "        Resized(keys=[\"image\", \"seg\"], spatial_size=spatial_size_conf, mode=('area', 'nearest')),\n",
    "        Spacingd(keys=['seg'], pixdim=1.0),\n",
    "        ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0, channel_wise=True),\n",
    "        EnsureTyped(keys=[\"image\", \"seg\"], dtype=torch.float),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675d8fc-0595-4059-973a-e1894add1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dataset = Dataset(data=train_files, transform=train_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a4232-0b9e-4cb2-9c0f-9c5674b056d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dataset[0]['seg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c688d-30be-4700-8656-98c180a9a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dataset[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060bc08-5333-45e5-8c71-18658bf304a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.set_device(2)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2a423-3a8e-4f38-a71d-717f3a2e9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_loader = DataLoader(check_dataset, batch_size=10, num_workers=0, collate_fn=list_data_collate, pin_memory=torch.cuda.is_available())\n",
    "check_loader = DataLoader(check_dataset, batch_size=4, num_workers=0, collate_fn=list_data_collate, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8d98d-e35d-4709-807a-b12b6011775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = monai.utils.misc.first(check_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d7710-9830-4f62-ada5-c5e156bbe677",
   "metadata": {},
   "source": [
    "### Check batch size in check_loader and number of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c9867-0c53-4340-ad5f-7ee157a9b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_data[\"image\"].shape, check_data[\"seg\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3202d4e1-43c2-4473-abc8-d06dd0459fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_example = check_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6702ed1-f77a-4fa3-b17b-b9df6ed3c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"image shape: {train_data_example['image'].shape}\")\n",
    "num_of_channels = len(feat_params)\n",
    "label_ind = round(np.where(train_data_example[\"seg\"]>0)[3].shape[0] / 2)\n",
    "label_pos = np.where(train_data_example[\"seg\"]>0)[3][label_ind]\n",
    "plt.figure(\"image\", (24, 6))\n",
    "for i in range(num_of_channels):\n",
    "    plt.subplot(1, num_of_channels, i + 1)\n",
    "    plt.title(f\"image channel {feat_params[i]}\")\n",
    "    plt.imshow(train_data_example['image'][i, :, :, label_pos], cmap=\"gray\")\n",
    "    plt.imshow(train_data_example[\"seg\"][0,:, :, label_pos],interpolation='none', cmap='Reds', alpha=0.3)\n",
    "    #plt.colorbar()\n",
    "plt.show()\n",
    "# also visualize the 3 channels label corresponding to this image\n",
    "print(f\"segmentaion shape: {train_data_example['seg'].shape}\")\n",
    "plt.figure(\"seg\", (4, 6))\n",
    "plt.imshow(train_data_example[\"seg\"][0,:, :, label_pos], cmap=\"gray\")\n",
    "#plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e33c9-6ebf-4bfe-8ea7-8e9dc0c05f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transf)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transf)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, num_workers=0, collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107360e-58b8-4bbd-932b-4cdf30456466",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 1\n",
    "train_files[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e03f6f8-d159-47b1-9cae-27721346e250",
   "metadata": {},
   "source": [
    "## Transform random rotate augmentation example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c72616-6e3d-4826-acc2-f18366c30015",
   "metadata": {},
   "source": [
    "### Before augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c7142-5cb4-4fdd-83ba-13cbc796819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_img\n",
    "plot_img = plot_img(train_files[ind]['seg'],\n",
    "         bg_img=train_files[ind]['image'][0],\n",
    "         threshold=0.1, alpha=0.5, display_mode='z')\n",
    "plot_img\n",
    "print(plot_img.cut_coords) # get coordinate of z where lesion center mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d160840-ff55-4835-b80b-b66c30afa611",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5333f2d-43ef-486a-9363-afd26b476513",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "for i in range(7):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    item = train_loader.dataset[ind]\n",
    "    image, segme = item[\"image\"], item[\"seg\"]\n",
    "    lab_loc = round(np.where(segme>0)[3].shape[0] / 2)\n",
    "    lab_pos = np.where(segme>0)[3][lab_loc]\n",
    "    plt.imshow(np.rot90(image[0,:, :, lab_pos]), cmap='gray')\n",
    "    plt.imshow(np.rot90(segme[0,:, :, lab_pos]), cmap=\"Reds\", alpha=0.4)\n",
    "    plt.title(\"seg overlay\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8bd97-5d49-4ba3-893c-277c6f82205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_loader.dataset.data[0]['seg'].split('/')[6].split('.')[0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a879e56-c227-41d6-a7e8-aa8d8a0b4abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset.data[0]['image'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4b60a-7078-4384-b47d-ef1afeab8088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_epoch(model, \n",
    "                criterion, \n",
    "                opt, \n",
    "                config, \n",
    "                dataloader, \n",
    "                device, \n",
    "                writer, \n",
    "                epoch, \n",
    "                metric_dict_epoch, \n",
    "                n_iters_total=0,\n",
    "                augmentation=None, \n",
    "                is_train=True):\n",
    "\n",
    "\n",
    "    # use amp to accelerate training\n",
    "    if config.opt.use_scaler:\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    phase_name = 'train' if is_train else 'val'\n",
    "    loss_name = config.opt.criterion\n",
    "    metric_dict = defaultdict(list)\n",
    "    target_metric_name = config.model.target_metric_name \n",
    "\n",
    "    if not is_train:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "\n",
    "    # used to turn on/off gradients\n",
    "    grad_context = torch.autograd.enable_grad if is_train else torch.no_grad\n",
    "    with grad_context():\n",
    "        iterator = enumerate(dataloader)\n",
    "        val_predictions = {}\n",
    "        for iter_i, data_tensors in iterator:\n",
    "            \n",
    "            brain_tensor, label_tensor = data_tensors['image'], data_tensors['seg']\n",
    "            #mask_tensor = brain_tensor\n",
    "            t1 = time.time()\n",
    "\n",
    "\n",
    "            brain_tensor = brain_tensor.to(device)\n",
    "            label_tensor = label_tensor.to(device)\n",
    "            #mask_tensor = mask_tensor.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            with autocast(enabled=config.opt.use_scaler):\n",
    "                label_tensor_predicted = model(brain_tensor) # -> [bs,1,ps,ps,ps]\n",
    "\n",
    "                loss = criterion(label_tensor_predicted, label_tensor) \n",
    "\n",
    "\n",
    "            if is_train:\n",
    "                opt.zero_grad()\n",
    "\n",
    "                if config.opt.use_scaler:\n",
    "                    scaler.scale(loss).backward()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                \n",
    "                if hasattr(config.opt, \"grad_clip\"):\n",
    "                    if config.opt.use_scaler:\n",
    "                        scaler.unscale_(opt)\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                                           config.opt.grad_clip)\n",
    "\n",
    "                metric_dict['grad_norm'].append(calc_gradient_norm(filter(lambda x: x[1].requires_grad, \n",
    "                                                model.named_parameters())))\n",
    "\n",
    "                if config.opt.use_scaler:\n",
    "                    scaler.step(opt)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    opt.step()\n",
    "\n",
    "\n",
    "            t2 = time.time()    \n",
    "            dt = t2-t1 # inference time\n",
    "            \n",
    "            metric_dict[f'batch_time'].append(dt)\n",
    "            metric_dict[f'{loss_name}'].append(loss.item())\n",
    "            #label_tensor_predicted = label_tensor_predicted*mask_tensor\n",
    "            dice_score = DiceScoreBinary(label_tensor_predicted, label_tensor)\n",
    "            coverage = (label_tensor_predicted*label_tensor).sum() / label_tensor.sum()\n",
    "            \n",
    "            if not is_train:\n",
    "#                #label = dataloader.dataset.labels[iter_i]\n",
    "                 #label = dataloader.dataset[iter_i]['seg']\n",
    "                label = dataloader.dataset.data[iter_i]['seg'].split('/')[6].split('.')[0]\n",
    "                val_predictions[label] = label_tensor_predicted.detach().cpu().numpy()\n",
    "            \n",
    "            metric_dict['coverage'].append(coverage.item())\n",
    "            metric_dict['dice_score'].append(dice_score.item())\n",
    "            \n",
    "            #########\n",
    "            # PRINT #\n",
    "            #########\n",
    "            message = f'For {phase_name}, iter: {iter_i},'\n",
    "            for title, value in metric_dict.items():\n",
    "                if title == 'grad_norm':\n",
    "                    v = np.round(value[-1],6)\n",
    "                else:\n",
    "                    v = np.round(value[-1],3)\n",
    "                message+=f' {title}:{v}'\n",
    "            print(message)\n",
    "\n",
    "            # print(f'Epoch: {epoch}, Iter: {iter_i}, \\n \\\n",
    "            # Loss_{loss_name}: {loss.item()}, Dice-score: {dice_score.item()}, \\n \\\n",
    "            # time: {np.round(dt,2)}-s')\n",
    "\n",
    "            if is_train and writer is not None:\n",
    "                for title, value in metric_dict.items():\n",
    "                    writer.add_scalar(f\"{phase_name}_{title}\", value[-1], n_iters_total)\n",
    "\n",
    "            n_iters_total += 1\n",
    "\n",
    "    target_metric = 0\n",
    "    for title, value in metric_dict.items():\n",
    "        m = np.mean(value)\n",
    "        metric_dict_epoch[phase_name + '_' + title].append(m)\n",
    "        if title == target_metric_name:\n",
    "            target_metric = m\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(f\"{phase_name}_{title}_epoch\", m, epoch)\n",
    "            \n",
    "    #####################\n",
    "    # SAVING BEST PREDS #\n",
    "    #####################\n",
    "    target_metrics_epoch = metric_dict_epoch[f'val_{target_metric_name}']\n",
    "    if not is_train:\n",
    "        if config.dataset.save_best_val_predictions:\n",
    "            # use greedy-saving: save only if the target metric is improved\n",
    "            if len(target_metrics_epoch) == 1 or target_metrics_epoch[-1] >= target_metrics_epoch[-2]:\n",
    "                for label, pred in val_predictions.items():\n",
    "                    #torch.save(pred, os.path.join(config.dataset.val_preds_path, f'{label}'))\n",
    "                    torch.save(pred, os.path.join(config.dataset.val_preds_path, f'{label}'))\n",
    "\n",
    "\n",
    "    return n_iters_total, target_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe55b6-3e89-4f9c-9bcb-8623bb829d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Image with one epoch iterator\n",
    "\"\"\"\n",
    "def one_epoch(model, \n",
    "                criterion, \n",
    "                opt, \n",
    "                config, \n",
    "                dataloader, \n",
    "                device, \n",
    "                writer, \n",
    "                epoch, \n",
    "                metric_dict_epoch, \n",
    "                n_iters_total=0,\n",
    "                augmentation=None, \n",
    "                is_train=True):\n",
    "\n",
    "    plt.figure(figsize=(30,30))\n",
    "    # use amp to accelerate training\n",
    "    if config.opt.use_scaler:\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    phase_name = 'train' if is_train else 'val'\n",
    "    loss_name = config.opt.criterion\n",
    "    metric_dict = defaultdict(list)\n",
    "    target_metric_name = config.model.target_metric_name \n",
    "\n",
    "    if not is_train:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "\n",
    "    # used to turn on/off gradients\n",
    "    grad_context = torch.autograd.enable_grad if is_train else torch.no_grad\n",
    "    with grad_context():\n",
    "        iterator = enumerate(dataloader)\n",
    "        val_predictions = {}\n",
    "        for iter_i, data_tensors in iterator:\n",
    "            image, segme = data_tensors['image'], data_tensors['seg']\n",
    "            \n",
    "            plt.subplot(1, 11, iter_i+1)\n",
    "            lab_loc = round(np.where(segme>0)[4].shape[0] / 2)\n",
    "            lab_pos = np.where(segme>0)[4][lab_loc]\n",
    "            plt.imshow(image[0, 0,:, :, lab_pos], cmap='gray')\n",
    "            plt.imshow(segme[0, 0,:, :, lab_pos], cmap=\"Reds\", alpha=0.4)\n",
    "            plt.imshow(image[0, 2,:, :, lab_pos], cmap=\"Greens\", alpha=0.2)\n",
    "            #torch.Size([2, 3, 128, 128, 128]) torch.Size([2, 1, 128, 128, 128])\n",
    "            if iter_i > 10:\n",
    "                break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106e0e9b-1701-45f3-be29-f326b6a9a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config.opt.criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5c21c-12ff-4f65-b241-fb75901d474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "from losses import DiceScoreBinary,\\\n",
    "                   DiceLossBinary,\\\n",
    "                   symmetric_focal_loss,\\\n",
    "                sym_unified_focal_loss,\\\n",
    "                symmetric_focal_tversky_loss,\\\n",
    "                DiceSFL,\\\n",
    "                tversky_loss\n",
    "import torch.optim as optim\n",
    "from models.v2v import V2VModel\n",
    "from utils import save, parse_args, get_capacity, calc_gradient_norm\n",
    "from collections import defaultdict\n",
    "from IPython.core.debugger import set_trace\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "\n",
    "##########\n",
    "# LOGDIR #\n",
    "##########\n",
    "MAKE_LOGS = config.default.make_logs\n",
    "SAVE_MODEL = config.opt.save_model if hasattr(config.opt, \"save_model\") else True\n",
    "DEVICE = config.opt.device if hasattr(config.opt, \"device\") else 1\n",
    "device = torch.device(DEVICE)\n",
    "print(device)\n",
    "\n",
    "\n",
    "experiment_name = '{}@{}'.format(config.default.experiment_comment, datetime.now().strftime(\"%d.%m.%Y-%H\"))\n",
    "print(\"Experiment name: {}\".format(experiment_name))\n",
    "\n",
    "writer = None\n",
    "if MAKE_LOGS:\n",
    "    experiment_dir = os.path.join(config.default.log_dir, experiment_name)\n",
    "    if os.path.isdir(experiment_dir):\n",
    "        shutil.rmtree(experiment_dir)\n",
    "    os.makedirs(experiment_dir)\n",
    "    shutil.copy('configs/config.ini', os.path.join(experiment_dir, \"config.ini\"))\n",
    "    \n",
    "    # write .json dataset log\n",
    "    ds_split_log = {\"train\": train_subs_indcs,\n",
    "                    \"val\": val_subs_indcs}\n",
    "\n",
    "    with open(os.path.join(config.default.log_dir, experiment_name, 'train_test_split.json'), 'w') as f:\n",
    "        trvasp = json.dumps(ds_split_log)\n",
    "        f.write(trvasp)\n",
    "        f.close()\n",
    "\n",
    "    if config.dataset.save_best_val_predictions:\n",
    "        val_preds_path = os.path.join(experiment_dir, 'best_val_preds')\n",
    "        config.dataset.val_preds_path = val_preds_path\n",
    "        os.makedirs(val_preds_path)\n",
    "    writer = SummaryWriter(os.path.join(experiment_dir, \"tb\"))\n",
    "    \n",
    "#########\n",
    "# MODEL #\n",
    "#########\n",
    "if config.model.name == \"v2v\":\n",
    "    model = V2VModel(config).to(device)\n",
    "elif config.model.name == \"unet3d\":\n",
    "    model = UnetModel(config).to(device)\n",
    "capacity = get_capacity(model)\n",
    "\n",
    "print(f'Model created! Capacity: {capacity}')\n",
    "\n",
    "if hasattr(config.model, 'weights'):\n",
    "    model_dict = torch.load(os.path.join(config.model.weights, 'checkpoints/weights.pth'))\n",
    "    print(f'LOADING from {config.model.weights} \\n epoch:', model_dict['epoch'])\n",
    "    model.load_state_dict(model_dict['model_state'])\n",
    "\n",
    "\n",
    "################\n",
    "# CREATE OPTIM #\n",
    "################\n",
    "criterion = {\n",
    "    \"BCE\":torch.nn.BCELoss, # [probabilities, target]\n",
    "    \"Dice\":DiceLossBinary,\n",
    "    \"DiceBCE\":None,\n",
    "    \"DiceSFL\": DiceSFL(delta=config.opt.delta, gamma=config.opt.gamma),\n",
    "    \"TL\": tversky_loss(delta=config.opt.delta),\n",
    "    \"FTL\": symmetric_focal_tversky_loss(delta=config.opt.delta, gamma=config.opt.gamma),\n",
    "    \"SFL\": symmetric_focal_loss(delta=config.opt.delta, gamma=config.opt.gamma),\n",
    "    \"USFL\":sym_unified_focal_loss(weight=config.opt.weight, # 0.5\n",
    "                                     delta=config.opt.delta,  # 0.6\n",
    "                                     gamma=config.opt.gamma) # 0.5\n",
    "}[config.opt.criterion]\n",
    "opt = optim.Adam(model.parameters(), lr=config.opt.lr)\n",
    "\n",
    "#####################\n",
    "# ASSIGN DATALOADER #\n",
    "#####################\n",
    "train_dataloader = train_loader\n",
    "val_dataloader = val_loader\n",
    "\n",
    "#item = train_loader.dataset[ind]\n",
    "#image, segme = item[\"image\"], item[\"seg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ef997-4a16-4d2c-826a-71b6d02d91b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f54e32-5bd8-4484-9e94-b88f17152a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Start training!')\n",
    "metric_dict_epoch = defaultdict(list)\n",
    "n_iters_total_train = 0 \n",
    "n_iters_total_val = 0\n",
    "target_metric = 0\n",
    "target_metric_prev = -1\n",
    "try:\n",
    "    for epoch in range(config.opt.start_epoch, config.opt.n_epochs):\n",
    "        print (f'TRAIN EPOCH: {epoch} ... ')\n",
    "        n_iters_total_train, _  = one_epoch(model, \n",
    "                                        criterion, \n",
    "                                        opt, \n",
    "                                        config, \n",
    "                                        train_dataloader, \n",
    "                                        device, \n",
    "                                        writer, \n",
    "                                        epoch, \n",
    "                                        metric_dict_epoch, \n",
    "                                        n_iters_total_train,\n",
    "                                        augmentation=None, # augmentation None because compose in dataloader\n",
    "                                        is_train=True)\n",
    "\n",
    "        print (f'VAL EPOCH: {epoch} ... ')\n",
    "        n_iters_total_val, target_metric = one_epoch(model, \n",
    "                                        criterion, \n",
    "                                        opt, \n",
    "                                        config, \n",
    "                                        val_dataloader, \n",
    "                                        device, \n",
    "                                        writer, \n",
    "                                        epoch, \n",
    "                                        metric_dict_epoch, \n",
    "                                        n_iters_total_val,\n",
    "                                        augmentation=None,\n",
    "                                        is_train=False)\n",
    "\n",
    "        if SAVE_MODEL and MAKE_LOGS:\n",
    "            if not config.model.use_greedy_saving:\n",
    "                print(f'SAVING...')\n",
    "                save(experiment_dir, model, opt, epoch)\n",
    "            # use greedy-saving: save only if the target metric is improved\n",
    "            elif target_metric > target_metric_prev:\n",
    "                print(f'target_metric = {target_metric}, SAVING...')\n",
    "                save(experiment_dir, model, opt, epoch)\n",
    "                target_metric_prev = target_metric\n",
    "except Exception as e:\n",
    "    print(traceback.format_exc())\n",
    "    #set_trace()\n",
    "    # keyboard interrupt\n",
    "    if MAKE_LOGS:\n",
    "        np.save(os.path.join(experiment_dir, 'metric_dict_epoch'), metric_dict_epoch)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f7302-664d-4ca9-9d63-b6040e26a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subs_indcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e463c-9ee6-4c66-8c65-b370e2cf9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_val_preds = {}\n",
    "# for label in os.listdir(val_preds_path):\n",
    "#     val_preds_label_path = os.path.join(val_preds_path, label)\n",
    "#     best_val_preds[label] = torch.load(val_preds_label_path)[0,0]\n",
    "experiment_name = 'v2v-AUG_YARKIN_onesite-subs_autocast_DICE-loss_lr-1e-3_t1+flair+thick+blurt1@22.06.2022-19'\n",
    "val_preds_path = os.path.join('./logs',experiment_name, 'best_val_preds')\n",
    "best_val_preds = {}\n",
    "for label in os.listdir(val_preds_path):\n",
    "    experiment_name = 'v2v-AUG_YARKIN_onesite-subs_autocast_DICE-loss_lr-1e-3_t1+flair+thick+blurt1@22.06.2022-19'\n",
    "    best_val_preds_path = os.path.join(val_preds_path, label)\n",
    "    best_val_preds[label] = torch.load(best_val_preds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9edd25-bdd4-48fa-a7e6-e41946021624",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_preds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef445e84-99f0-44a7-b6c9-17b8ea59caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "ind_pred = str(29) # index for best val score tensor\n",
    "ind = [i for i,x in enumerate(val_subs_indcs) if x == ind_pred][0]\n",
    "item = val_loader.dataset[ind]\n",
    "image, segme = item[\"image\"], item[\"seg\"]\n",
    "#label_tensor_predicted = val_loader.dataset[ind]['seg'].clone().detach()\n",
    "new_arr = best_val_preds[ind_pred][0][0]\n",
    "#new_arr = np.where(best_val_preds[ind_pred][0][0] > 0.1, best_val_preds[ind_pred][0][0], 0)\n",
    "lab_loc = round(np.where(segme>0)[3].shape[0] / 2)\n",
    "lab_pos = np.where(segme>0)[3][lab_loc]\n",
    "\n",
    "plt.figure(figsize=(30,7))\n",
    "for i in range(20):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(np.rot90(image[0,:, :, i*6]), cmap='gray')\n",
    "    plt.imshow(np.rot90(new_arr[:, :, i*6].astype(np.float)), cmap=\"jet\", alpha=0.5)\n",
    "    plt.imshow(np.rot90(segme[0,:, :, i*6]), cmap=\"Greens\", alpha=0.4)\n",
    "    plt.title(f\"Axial Image Slice # {i*12}\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30,7))\n",
    "for i in range(20):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(np.rot90(image[0,:, i*6, :]), cmap='gray')\n",
    "    plt.imshow(np.rot90(new_arr[:, i*6, :].astype(np.float)), cmap=\"jet\", alpha=0.5)\n",
    "    plt.imshow(np.rot90(segme[0,:, i*6, :]), cmap=\"Greens\", alpha=0.4)\n",
    "    plt.title(f\"Sagital Image Slice # {i*12}\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(30,7))\n",
    "for i in range(20):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(np.rot90(image[0,i*6, :, :]), cmap='gray')\n",
    "    plt.imshow(np.rot90(new_arr[i*6, :, :].astype(np.float)), cmap=\"jet\", alpha=0.5)\n",
    "    plt.imshow(np.rot90(segme[0,i*6, :, :]), cmap=\"Greens\", alpha=0.4)\n",
    "    plt.title(f\"Sagital Image Slice # {i*12}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False)\n",
    "dice_metric(y_pred=pred_tensor, y=segme[0])\n",
    "pred_tensor = torch.Tensor(new_arr)\n",
    "metric = dice_metric.aggregate().item()\n",
    "print(f\"Dice {metric}\")\n",
    "\n",
    "#plt.figure(figsize=(20,7))\n",
    "#sns.distplot(best_val_preds[ind_pred][0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
